{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "project07.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyE4PY81lP1Y"
      },
      "source": [
        "# 1. Environment setup "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLRjSLqJjJy8",
        "outputId": "8c7cdebb-9993-4e64-ac92-73647c413913"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ori9DPB4k_ei",
        "outputId": "80518a77-5420-432f-85ed-895122f7d079"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install syllabipy"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.12.5-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 9.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.1.2-py3-none-any.whl (59 kB)\n",
            "\u001b[K     |████████████████████████████████| 59 kB 6.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 54.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 23.5 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 53.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.1.2 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.12.5\n",
            "Collecting syllabipy\n",
            "  Downloading syllabipy-0.2.tar.gz (3.9 kB)\n",
            "Building wheels for collected packages: syllabipy\n",
            "  Building wheel for syllabipy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for syllabipy: filename=syllabipy-0.2-py3-none-any.whl size=5813 sha256=8b27b4c54e9e2bd77ecbf53985c1885043afc2ad62c6896fb0c625f9a74e1087\n",
            "  Stored in directory: /root/.cache/pip/wheels/5a/43/1a/9078e0df36fa76df8c584c20b0eeb924ad8686d240b1a9646a\n",
            "Successfully built syllabipy\n",
            "Installing collected packages: syllabipy\n",
            "Successfully installed syllabipy-0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dg5HUD5qlVZz"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "import random\n",
        "import time\n",
        "import datetime\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, GPT2Config, AdamW, get_linear_schedule_with_warmup\n",
        "from torch.utils.data import Dataset, random_split, DataLoader, RandomSampler, SequentialSampler\n",
        "from syllabipy.sonoripy import SonoriPy\n",
        "from transformers import BertTokenizer\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMPk8ZK4m81D"
      },
      "source": [
        "# 2. Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5T_eUwFnEGN"
      },
      "source": [
        "poem_df = pd.read_csv(\"/content/limricks_end_with_[SEP]_sep_with_-.csv\")\n",
        "poem_df = poem_df.fillna(\"\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfjZyII0nYOZ"
      },
      "source": [
        "# 3. Process Text and Create Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPQfTHBEzYJA"
      },
      "source": [
        "batch_size = 16\n",
        "epochs = 20\n",
        "max_len = 60\n",
        "device = torch.device('cuda')\n",
        "learning_rate = 1e-4\n",
        "eps = 1e-8\n",
        "syl_num = 5\n",
        "word_embed_dim = 256\n",
        "syl_embed_dim = 64\n",
        "total_embed_dim = word_embed_dim + syl_embed_dim * syl_num"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jrm-aur0nbll",
        "outputId": "2e46a801-ce89-4340-9b85-0e092765d822"
      },
      "source": [
        "word_tokenizer = BertTokenizer.from_pretrained(\"/content/tokenizer[SEP]--vocab.txt\")\n",
        "syl_tokenizer = BertTokenizer.from_pretrained(\"/content/fre_1_syllables-vocab.txt\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1645: FutureWarning: Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated and won't be possible anymore in v5. Use a model identifier or the path to a directory instead.\n",
            "  FutureWarning,\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0p3SxBZU7rWd",
        "outputId": "277a66c2-07f5-4212-c219-19f1c82ca75f"
      },
      "source": [
        "print(\"Length of word_tokenizer : {}\".format(len(word_tokenizer)))\n",
        "print(\"Length of syl_tokenizer : {}\". format(len(syl_tokenizer)))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of word_tokenizer : 30003\n",
            "Length of syl_tokenizer : 22383\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bA4PHl0W8duG"
      },
      "source": [
        "class PoemDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, data, tokenizer, max_length=max_len):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "        self.data = data\n",
        "        \n",
        "    def __len__(self):\n",
        "        \n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        encodings_dict = self.tokenizer(self.data[idx],\n",
        "                                        truncation=True,\n",
        "                                        max_length=self.max_length,\n",
        "                                        padding='max_length'\n",
        "                                        )\n",
        "        input_ids = encodings_dict['input_ids']\n",
        "        if None in input_ids:\n",
        "          input_ids = torch.zeros(self.max_length)\n",
        "          attention_mask = torch.zeros(self.max_length)\n",
        "        else:\n",
        "          input_ids = torch.tensor(encodings_dict['input_ids'])\n",
        "          attention_mask = torch.tensor(encodings_dict['attention_mask'])\n",
        "        input_ids = input_ids.type(torch.LongTensor)\n",
        "        return input_ids, attention_mask        "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qc12VnG2_YRz"
      },
      "source": [
        "poem_dataset = PoemDataset(poem_df.iloc[:, 0].values, word_tokenizer, max_len)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKEeoLPzncvE"
      },
      "source": [
        "# 4. Train/Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkrDnJPYnv0c"
      },
      "source": [
        "# 5. Instantiate DataLoaders and Define Model Creation Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2UbCalrn3Jk"
      },
      "source": [
        "poem_dataloader = DataLoader(poem_dataset, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4PYdsFnwpWF"
      },
      "source": [
        "max_poem_length = max([len(word_tokenizer.encode(poem)) for poem in poem_df.iloc[:, 0].values])"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYhIZ1VNyFcX"
      },
      "source": [
        "a = [len(word_tokenizer.encode(poem)) for poem in poem_df.iloc[:, 0].values]"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "0MBno5R5yh2y",
        "outputId": "71d28c7c-1fdb-46c1-ae5c-b3f2d2d17167"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(a)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fe6ca392190>]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXgUVboG8PfLTjZCSAj7jqwuSIZFkF1FHUXvOHOVGWUUr446jjsi4jjOdRxc7riMDKgwgqOoCCiKArLvBMK+BQgQIMgSdhJMCOHcP7q6U91dvXfS3dXv73nypLu6uvp0LV+d851T1aKUAhERmUtMqAtARETBx+BORGRCDO5ERCbE4E5EZEIM7kREJhQX6gIAQFZWlmrZsmWoi0FEFFHWr19/QimVbfRaWAT3li1bIj8/P9TFICKKKCJywNVrTMsQEZkQgzsRkQkxuBMRmRCDOxGRCTG4ExGZEIM7EZEJMbgTEZkQgztRAMorqzB9fTF462wKN2FxERNRpBo7pwCTVxUhOy0R/a4wvFCQKCRYcycKwPHz5QCA0vJLIS4JkT0GdyIiE2JwJyIyIQZ3IiITYnAnIjIhBnciIhPyGNxF5N8iclxEtummZYrIfBHZo/2vp00XEXlPRApFZIuIXFuThSciImPe1NwnAxjiMG0UgIVKqXYAFmrPAeBmAO20v4cAjA9OMYmIyBceg7tSahmAUw6ThwKYoj2eAuAO3fRPlMUaABki0ihYhSUiIu/4m3PPUUod0R4fBZCjPW4C4JBuvmJtmhMReUhE8kUkv6SkxM9iEBGRkYA7VJXlpho+31hDKfWhUipXKZWbnc3LtomIgsnf4H7Mmm7R/h/Xph8G0Ew3X1NtGhER1SJ/g/u3AIZrj4cDmKWbfp82aqYngLO69A0REdUSj3eFFJHPAfQHkCUixQBeBjAWwDQRGQHgAIDfaLP/AOAWAIUALgC4vwbKTEREHngM7kqpe1y8NMhgXgXgsUALRUREgeEVqkREJsTgTkRkQgzuREQmxOBORGRCDO5ERCbE4E4UgIuXLoe6CESGGNyJArBgp+Xi7BOlFSEuCZE9BneiICituBTqIhDZYXAnIjIhBnciIhNicCciMiEG9yh1orQC58orQ10MIqohDO5RKvfVBej990WhLoZpiIS6BET2GNyj2HmO8CAyLQZ3IiITYnAnIjIhBnciIhNicCciMiEGd6IgEHC4DIWXiA/uZRWXUF5ZFepiEBGFlYgP7p1fnofuf1sQ6mIQEYWViA/uAHCunOO1iYj0TBHciYjIHoM7URDw9gO1o7yyir9+5SUGdyKKGB1emot+by4OdTEiAoM7EUWUI2fLQ12EiMDgTkRkQgzuREHAlDuFGwZ3oiBghyqFGwZ3IiITYnAnIjIhBnciIhMKKLiLyFMisl1EtonI5yKSJCKtRCRPRApF5EsRSQhWYYmIyDt+B3cRaQLgTwBylVJdAMQCuBvA6wDeVkq1BXAawIhgFJSIiLwXaFomDkAdEYkDkAzgCICBAKZrr08BcEeAn0EU9ng/dwo3fgd3pdRhAG8BOAhLUD8LYD2AM0op620aiwE0MXq/iDwkIvkikl9SUuJvMYiIyEAgaZl6AIYCaAWgMYAUAEO8fb9S6kOlVK5SKjc7O9vfYhBRFGs56nuM/nprqIsRlgJJywwGsF8pVaKUqgQwE0BvABlamgYAmgI4HGAZiYhcmpp3MNRFCEuBBPeDAHqKSLKICIBBAHYAWAzgLm2e4QBmBVZEMrOnp21Cy1Hfh7oYAeMVqhRuAsm558HScboBwFZtWR8CeB7A0yJSCKA+gElBKCeZ1MwNbNgR1YQ4z7O4ppR6GcDLDpP3AegeyHKJKPju/3gt9paUYdnIAaEuCtWCgII7EUWOxbs4Ki2a8PYDREQmxOBORGRCDO5ERCbE4E5EZEIM7kREJsTgTkRkQgzuREEguktUH5u6Afd/vDaEpSHiOHeioPt+y5FQF4GINXcKndlbfgp1EYKGt5ahcMPgTiHz2vc7Q10EItNicCciMiEGdwoZFeoCEJkYgzsRkQkxuFPIKBNV3fljHRRuGNwpZBQTM0Q1hsGdiMiEGNwpZMyUlqkNc7cdwdBxK6G44sgLvEKVKEI8NnUjqi4rVF1WiItlkp/cY82dosrYOQUYO6egVj9z06EzuPnd5fj5YlWtfi5FNwZ3CplQJBcmLN2LCUv3Bn257urRr87egZ1HzmHbT2cD+gxrOkY4NIe8wOBOIcPUsW+sq4uhnbzB4E4hxOjuC54MyRcM7kQ1LNgxmVkZ8gaDO1EQeJMHD1ZMZs6dvMHgTiHDNANRzWFwp5CJlthePcolxAWhqMLgbkJvzdsVEb9yZKYrLd0F7upvyejuraW7S/DyrG2hLkZE4xWqJvT+4kIAwC+vahzikhD5Z/i/LT8w/srQLiEuSeRizZ3C0tkLlXjk0/U4c+FiqIsSMBM1UCiCMLhTyLiLef9euR9zth3FxyuLaqs4AfEm4cKcO9WmgIK7iGSIyHQRKRCRnSLSS0QyRWS+iOzR/tcLVmGp5lRWXcbI6Ztx+MzPtfaZrNES1ZxAa+7vApirlOoA4GoAOwGMArBQKdUOwELtOYW5FYUnMC2/GKNnbq21z3TXoWqmuM/bBlAo+B3cRaQugL4AJgGAUuqiUuoMgKEApmizTQFwR6CFpOhlilQGb/hFIRBIzb0VgBIAH4vIRhGZKCIpAHKUUke0eY4CyDF6s4g8JCL5IpJfUlISQDEoKMxUVSaigIJ7HIBrAYxXSnUFUAaHFIyytLsNw4ZS6kOlVK5SKjc7OzuAYnhnb0kp/v7DTlONra4JtVm5dLslwnQ7rSo8gX+v2B/qYhB5FEhwLwZQrJTK055PhyXYHxORRgCg/T8eWBGD4/6P1+GDZftqtcOQPPAifkuYZaqHTczDX2fvcH7BzVkxPE9TZHZ+B3el1FEAh0SkvTZpEIAdAL4FMFybNhzArIBKGCRVl3mIGZm4fB8AQIUgBEXbFgmv0xSZXaCjZR4H8JmIbAFwDYDXAIwFcIOI7AEwWHseNsK0tR8yr36/0+55uAQgM20m7nMUCgEFd6XUJi1vfpVS6g6l1Gml1Eml1CClVDul1GCl1KlgFTZcjVtciN3Hzoe6GKYUyQNMvlh7EEB1qyiSv0s4OHuh0uf3HD1bjrFzCnA5ClvuUXeFarAPsMqqy3hz3i7cMW5lcBdcy0JRu3Q7zl17KZLj4SiHawbCrf8g0oydu9PzTA6enrYJE5buxfqDp2ugROEt6oJ7TQWxi5cu18yCTczdpgiX2u6J0gq8PrfAY58Nw3bNq6zy/eC1HpfRmBqLuuBO5IvRM7di/JK9WFF4wu9lRGNgCRe2q4Oj8OzL4G5iszYdRt6+kz69pzavonQX9MIlIFZoNb/LQSjQ0t3HMW/70YCXQ85en1uAsopLTtNtP5RS2wUKA7yfu4k98cUmAEDR2FtDXBL/hfqS/WCcY6znhbd+3A3Av+1xqYppP3fGL9kLpYBRN3ewm86aOwUsTCqafgtJh6qbtfafNQdqsSSeBRIbfF21q/aewNxt9jV8/Unuw2V7g3ox3oz1xdh86EzQlldTPO2j7vu9qtffkbM/Y8LSvaa/Wp3BPUBmqxDU5vdxd2ydL3duYodCKALAsI/y8IdP19tN02+X134owIjJ64L2ec98tRlDI3y0lytGm++hT9Zj7JwCFJ28UPsFqkVRE9yDUdMpOlGGT8OsRlmbyiur8O6CPai4VGU3/ZPVRTh0ypwHyhqtz8JTeqimm/2Oyy+76P/J7+uNxQGWpmZ9v+WI4fTle9zfYPB8ufM4eKO0jDU3H4x+lHAWNcE9GP5r/CqM+WabKfOf3uzmk1bsx9sLdmOy7teRSisu4c+ztuPuD9fUyGeGmrfD72p6DLvjySUmgLPJU19uDrQ4NeqxqRsMpx8/X+H2fV+tNzhpRXGHalQE9/LKKs8zeeG09nuewe7kq7hUhXGLCw1zhjt+OofvNv9UY8t35O6r/XPRHgDAhYvV69Na+zn3s+9XD4aDAyfL8OW6gwEv51RZBSYu32eYxvE3taOUwrqiU1hc4HzvPU97YGXVZYxbXBjQvj97y0/Y/tNZv9/vj1V7/R9yqrd8TwlWFZ7Q1dyjL7xHxWiZD5buC+rygr2bTF5ZhDfn7UJcjODhfm3sXrvlveUAgNuubuz38j9atg9v/bgbdeJj8UCfVn4t41x5JcorLSeHhQXH8NQNV/hdHhtv7gpZw8fknf9ahVNlF/Hrbs0QE+P/h1lHwjTOqBOsomFF4QncO2ktAOcRNp6C1dS8g3hz3i5UVl3Gk4P921Z/nLrR8LNr0rCP8jzP5AXreruySV0AxsesybMy0VFzDyQ/qed+XLbCxyv343TZRZ+Xa60Jl10MrIVRXlmFD5budZpuXe7PAdTilK7SX1Hp3ALw5zjx5k6U87Yfw84j52zPVxWesOXBg+GUl9vL27B/wY9tuHxPCdYVnXLafp+tqW5RONbAPZXHus+XG2wrADjooTNx2rpDtse1dd8kTzl1vV1Hz7vMzRuxngsX7jyGfSfK7F5bsecE1hWZ7xZYURHca2PEw2UFvPLdDjw33fd8ZrBqp+OX7MXf5xQ4Ta/Jr1/Tjd3Nh87g5neX254Pm5jnV37flWC3DIw66Tyt/3snrcWvJ6zGhKX222+u7oKncYsL7d/kody2e/O4mO/Of7keHVNeWYWRM7bYnt/49jL3HxYk1tq2N256Z5nL3LyeYwVixJR8p3l+NykPv56w2uvPjhRREdzP6O4mpxQwZVURzhn0rBv5fO1BnCh135Gjd1r7rH0lpYY1i9NlF3H9G4tQadQpqx2RZy5cxH/WHHB7Ulq86zi2HbbPh3oaPugukLn6rHVFp/DA5HW4qCuv0ZylFZcw5J1lPp1I9bMWHi+1PT56ttxw/uPnjae7Xr6lNVWqjY5wXF9283pYltcnAYcFFRw9h11e1nxPlrpuRZQ6XH3pqTiLtDz9+CV7McOgo/GkixbLl+sO4tg539ZzOLPuY/9avBcTDFq1jsorqzBx+T6P9xL6ZuNhv0aIrd57Evm11EqIiuCu70XP238SL3+7HWO+3ubxfQdOluGFmVvx6KeeawhW1uA26B9LDWsWXf93Pg6d+hl/+E/1OGbHkRbPTNuMl77Zhu0/nXN8u839H6/DL/+5wv6zXYQo336Iw74sv56wGosKjmOS7qflXAXwgqPn8YWuOe+Lwf9Yant87yTjvOuIyc61LneW7C7BK9/twKvaLyc5ri8g+C0Px5r7kHeWu5jTmS8XbnnKua8/UH0XxGe+cm5NGr392LlyPD9jq2HtNlJZN8fc7Ucx1qBV6+jtBbvx6vc78e3mw27ne/LLTbjzX6t8Ls89H63BXbXUSjBlcP9i7UG8Oc+yIR2v9CvXRoxsKT6D+/691m0N/uuNlg28tugUjpytHievYDkQV+89idUu8r/Wnaq8sgqfrC5yup/0ibKLWL33JDYfOmMbhWOdw9pS0Acjb+5H7arSvOmg5epDV8P1pq07ZNe6MVJaoWv9APjP6iK8PGsbvsq3rxWWaq2HY+fK8c1G1wfIhoOnccnFdzrookZUohsKd1YbnTMt/xDeXbAHFy5ewqWqy5i8cr+tVfSzlv/25oRjdMLS57l3HjnnVHs2XI7HOYIjgL5fAMYnNet6M2qpets3EWqO/QPutsf8Hcecpi0psOT9yyo895340qIPBVOOlrHeR/vZG9s7XelnjYBFJy+g6OQFjJ65Fe8Pu9ZwOe8s2GN7rM/zriw8gZe+Ma75O+5M//fjLny0fD/qpyTi1qsa2abHiOUsrrdf6+jZXOycPvh+6xGPI2Zc1ajz9rtvBurzq67oTwz7Ssrw0qztxmXQ1sC9k/Kw+1gpBnZsgPSkeKf5/stNrafCxZDNo7p0wagZWzD6lo4YOd1S9pLScrTPScNfvtuBC5VVeLR/W6/6GkTE5VnxrXm7bI9f+6EAu46WGs6nV1sjMAIdV29U87dOM6pIPP75Bnz2YM+APrM23Pj2MrvRPe7ShK/PLcAj/e1Hp1lTaGYYSGOamvsebaPsK6k+AL0Z2zp7yxGnK9u2Fp/FWoeAqM9DuqvBOR4X1hx83v6T6PnaQtv0jQed7+Xhbhz6hYuX8P2WI27zoZ52yAtejBradOg0Nhj8sMEBL/OL1u+/+5hlO1hH2awrOoXNh85g4c5jKHIYreCNv3xrfzIpOHoeMzZUtxo+XXPQtk5/2Grp6/hm02Hd/PYprvLKKnyWd8CWW5269qDTCJIdR+zfc6qsuqb2xtwCwxy+tRUWbEt32Y8kcZfH96ZGaXRkWKcZ7Ucnznv/vTYfOuMyrzxn6xH8ZHC1+OtzPadMvLXJh/vk6I/l9Qd0ZVYKn+Ud8HidgP4ahO0/nUXfNxZjpXZ76FV7T2CHLrWqb/3XBtME9xu0Hv2B/7fU7XxGO+4Yh1r4be+vwG8+sM+L6WtKbi9bVsouSFvf9cnqA3Y1T19VXLqMx6ZuwD1uRop4qjX+c1Gh+xkAnCi9aFirXrbb+2FqRn49YTWGjluJEVPy0f+tJT6/f/KqIrvn+0+U2bWsAGCmlgbadvgcjpz92a7Z7Zj7/r8fd+FFXb/Ln2dtt8v7A8Cqva6HXP5ryV7DHP6butp+MDkO33Mn99UFHucxqveIu+jug6HjVrrMKz/y2Qan/av49AWMX+K5s9Nbvvwq2lNfbrI9/tX46jL/uOMYXvx6G96Y67w99a2B+3X3+Ln1vRU4eOoCfjvR0mc07KM823UqAHDX+NodkWOqtIw3Q6OMaser955ExaUqTFqxH80zkw3fpx/d4m587ebis3ZXPFprkd74cccx9Hl9keFrf9N+yHrfiTI8P706jTI17yBmbijGsB7NveqQy9t3Ek3qeXehzUY/fprM6AQzd5t360Ap5dTy8dcTn29y+7rRaJGLVZfx7eafsPvoecMT8fI9wbl68j+ri1BSehH3dG8W0PdVSuGr9cUQAAlxMUhPikd8rHF9zfEq3MoqhR0/nbNrCVpP/ucNWqaXlYJSCtPXF+PWqxohOSEO2w6fRcWlKnRrkWmbT19TPV9eibSkeJworcDa/adwy5WWtOTRc+UYNWMLHunfBi3qp7hMwwHA7e+vwLSHe+HDZf5diFhw1P1IJVe1aeu2dmyJLSo4hrbZaX6VxfH+Vu8u2IO8/SfxyQPdEediuwXCVMHdm4sanMYLw3LPivcW7sG4xa5rD/rOvznb3P/ggj4f7euFScWnjXc2/QHwZX51B+Hory39C/kHvAvE//3hGqQmerfZ/RkNoKDsUmMVVVX4g5ejjZbsLnE5DNJXa/0cbvanzze6fM1VB7CvrPvHV/mH3AY2T178Zhum5nl364TnZ2x1mqavVQJwu6w9x0uxau9JPDd9CzYeOoPX7rzS1nLR57j1yxw1cyvGDbsWIyavw+bis9j40g22175YdwhfrDuEorG3um1xbik+i8c/32jY+RkM2w67HpFm5AGDEVvbDp9FF+1KWF+8vcByVfPkVUV48PrWPr/fk4gO7p7yYcY5UeNRIev2R88P6Hoz6sPfuzyOX7zXrr9ixnr3Q8r0PltzwK+DxB8zN3hfrppyJMAT2YGTvvddBMJ6/6Bp6w6hT9ss2/Q1+05ib0kpslIT7eb/fssRdGu+3zZA4IEpzrcprrqsPB7HNRXYvbF8Twk2HDyNsxcqja9NgWVUW6/W9e2mPasbfvrNxsPo3irT7vXfTqxOrwbz3vx6Eg43rM/NzVX5+b6PrR3zzVZ8uibwmz4RkWfvD+tqu99MsIy5tSNe1VKO0czf+/eIyHqlVK7RaxHdoXrkjHmupCMKd8EO7AAY2GtQRAf3hQa3QiUioggP7kREZIzBnYjIhBjciYhMiMGdiMiEGNyJiEyIwZ2IyIQCDu4iEisiG0Vktva8lYjkiUihiHwpIgmBF5OIiHwRjJr7EwD0VyK8DuBtpVRbAKcBjAjCZxARkQ8CCu4i0hTArQAmas8FwEAA07VZpgC4I5DPICIi3wVac38HwEgA1jvq1AdwRillvTNVMYAmRm8UkYdEJF9E8ktKArtXOBER2fM7uIvILwEcV0qt9zizAaXUh0qpXKVUbnZ2tr/FICIiA4Hc8rc3gNtF5BYASQDSAbwLIENE4rTae1MAob+3KhFRlPG75q6UekEp1VQp1RLA3QAWKaV+C2AxgLu02YYDmBVwKYmIyCc1Mc79eQBPi0ghLDn4STXwGURE5EZQfolJKbUEwBLt8T4A3YOxXCIi8g+vUCUiMiEGdyIiE2JwJyIyIQZ3IiITYnAnIjIhBnciIhNicCciMiEGdyIiE2JwJyIyIQZ3oggy78m+oS4CRQgGd6II0r5hWqiLQEEWIzW03JpZbO1oVDepxpbdvWVmjS2byMiiZ/p5Nd+Gl27war57ujfDx7//BSbf/wt0bZ4RSNGoBg29xvD3jAIW0cG9f/sGfr83zsPp8tEBbfxeNpE/6taJ92q+zBTvfnN+UIccDOjQAP3bN0CPVvUDKVrE6cAWTmQH978O7YyVowZ6Pb9+3i8e6on1YwZjwdPGtaVAThwAkJro+oabvVqH9kB7uF9rAMD17bIMX3/5tk745z1dMW7YtWifE9qDZMmz/d2+/vQNV9g991T7/evQzl59bkJcDJaPHICpD/bwukYdiCkPdMdlFdxlDu6UY3ssHpr+Mx7p5ddnTPhdN6dpNb2+1o4ehPVjBns17xt3XYXcFvXspv3vHV38+tym9erYHo/o0wpj/+tKl/Pe1DnH5Wu1JaKDe3xsDJpk1PE8o0Y/b+OMOqifmoi2DVKd5vO2ZuQoK7X6fTd2cr1xc1vWc/labWhc17IeUhKMT0D3926F265ujFuvaoRuIS5rdlqi29fr6bZVWmIcWmc7b0+9AV6etAd1aIBmmcm4rm0WWmenIiUh1vZay/rJ6N7K97Sd0b5mlZ2aCIUgR3cfdGvhXxoyLcl5H2pU1/tj0h8N0pNQP9X9ftFTq0D9omWmXVAGgE6N0n36vFitld+ifrJt2ku/7ISbuzRy+R5Xx5aRa5rVTMosooO71XVtLBvy4X6t8eG93VDwv0NczrvmhUGY/XgfNDY4KXRunI7P/6cnljzXHwCw6c83YP2YwVj0TD+n2sgTg9phoW7asucGYP5T1c8fG9gWS57tj68fvc7pc6w7y5VN6mL5yAG26SueH4DFz/bH/Kf64tU7uuAxP1JD1iD0/rCuHue9rDwHk77tLL9vmxAXg6/+YF+7C3TkxoN9Wnmcx10J80YPArTvcFPnHKx8wX0r7suHeiLLISiMurkDlo8cgHrJ9imRt//7Grvnq0cPwroXByNv9CDM/tP1mHK/8U8WNEhLxNLn+huum1mP9cbykQPstrkdhy+bEOvd4fm7ns2dps1+vI/dc1cV916t69ty+HmjB+EXupP5d3+sXsaaFwbh2RuvcHq/0S7ky0nqVYda9Hv3VO+33/+pj+Psdh7tb398vP6r6pr0k4PbYcmz/dEqK8U2bfQtHfDu3degWwvnCkvrrBTc1a2p4ee8crultZdRx77SVzc5HstHDsC2V26ytXyS4mOQP2YwYtykfZtnVp8kfvjT9bivVwuX8wbCFME9J93Ssdo+Jw03dm6IpPhYJMTZfzXr2bph3SR0aVLXcDldGtdFrzb1kZ5kOdAzkhNQPzURrbNTnWqEvdtmoY02rWfrTDSvn4xUXS0mRgQts1LQRldb69zYUoarmlo+v98V2Wim29BN6yWjVVYK2uWk4Xc9W+CaZr7Xmq01lsS4WJfzWMvd0YsajLU537ddNn7h0MlsHbnhWDPy1J9h1dCLDvH4WNfLyklPsm2X/u0b2LabKz1a13cKPNe3y0KzzGTEOwTSpHj79ZeeFI/stETkpCchNTEOdRKM12/dOvFoUT8F7Rum2U7iVimJcWiWmYxmmcnISbc/ydRLiUeSwzLrOpxw9EFB79YrG9vlmN+46yqnfdy6res7tEpv6pxja6nmpCchRZdOvFLbT7s2z0DDukkY0qWh02cbVRBiHHJA7vaH3/WsDmwD2mfj9qsb2567+r5WTRz2uxgRWzo0NsZy/AHV58zstESXnZe3XtUI9VONW+y28ht8jWaZyUhNjEM7LX15S5dGyEpNtB3jjlpnpeCe7s2199ZBp8bpEE85Mz8F5ZeYwtG60YNx9V9/BGCpEWcku061PNyvNT5Yus9jXtJq/lN9bRtz+cgBTrVBAFDaTp+eFI8lz/ZH2cVL6NAwHftPlKFtg1QseLqfrVaRP2awYc3qhk45GNA+G4t3lRiWY9rDvfCbD1bbTdN/h1WjBuK6sYuc3tenXRbmP9UXyYlxeHfhHogY18AA5/15/ZjBWFd02taUXDVqINKS4lBeeRmxMYJLVZeREBeDa/46H4Clttw6OxWvzy3A9PXF+P11LTF5VZHhZy14ui9SE+PR8+8LbdMS42Kx9Ln+6PfmEgDArleHoP2YubbXe7fNwo9P9UU7FymPqQ/2wLCJebbnjt+zc2Png3Dti4MMl+Vo3YuDsWDnMbwwc6tX87tjlMpwLKtRTfbfv89FrzbVfTjP3dQevzaogd52dWO0b5iGlvVTcMWYOQAsNfMuTexP8I7be/nIAbag17aBc/+LtYits1Iw5YHuUMr+xLh29CC7/WHmo9ehQVoijp4tdwrejkEuLSke614cjJNlFRjyznIkxcdgsYc+GHfE4Chr2yAVhcdLcdvVjTFjfTEAYHivFmhaLxl/+2Gn18u2HueNMiwVlnt7tsCfZ213mu+HJ65HYlwM2mSnBNyv54kpau5G6ibH29I1Teslu+3g7HeFJfXQqbF3ubh2uk7GZpnJhrU4fS2+ZVYKOjeui9gYseVd2zZItdXsslITXeYQHxvQ1nD61U3rGuZ99QHBKPWk/w7WFM6dboZiWZdxtVYTqZ+aiCFdGtpq3Y0z6iBNq9VmpiSgQXqS3Ym0R+v6yE5LRA+trNZO3NgYsbUgrNo2SEN6Heft1KJ+ddPaqEVyRU6aXWBonV09/3Vts+xypY61aatBHav7SBqkeTfENjst0YslqE0AAAyJSURBVFYLM+KurtC7jXFntl7HRtX7WdfmGUhzaJnkpCdiYAdLua37wp1dm7isCV6Rk4aEuBgkaq3atg1SPdYam2UmI9lN/thac2+qtUiaa+va2kp13B+ubV4PTeslI7dlJhpoLW5rK8b6HfStbut+BQCpifF2J8GWuv3CShnUUq7UWjGOLUwAttZoRp14W0u0T7ts/E/f1rZ+M2sL4EoXLX5bebJSbPunfr020PqNclvUQ1J8LEQEN3Zu6JRdCDbT1twBYOLwXBw7V+FxvuvaZGHOE9d7HD61dvQgt7k0PW8DhCe5ulTIhpduwInSCsTFiC0VZbV85ADExghe+mYbgOrAsunPN2DDwdN4Y+4uFBw9bzcqIiM5AQue7odmmXXwwi0d8Yu/LXD6/C5N6mLuk9fjCoNamy/u6tYUXZrURcdG6Vj9wkAkxcWiXkoC5jxxPRpn1MH58kq37//msd6GnXdGZj3WG7uOnre1jL57vA/OXrAsPyk+Foue6Ye4mBikJFafKF67sws+X3vQr++2fOQAHD9fgV+NX+VyHsex6X//1ZW477qWuGPcSpfvuatbU4y+pSOSE2KdWocrnh9gF+xf+mUn3NuzhdsTupU17hjlxn1OEWiLcHzXlw/3wqnSi14tYsXzAzFn21FbSibvhUEov1Tl8X2921qO24+W7cPMjYftyq5/PKJPK/Rum2WYhnzl9s4Y0aclGqQn4c6uTdCxUbptvvfu6YqfzvyM1tmptmPgN7nNcPHSZa++14xHeuFX4y0t66XP9Tds4dck09bcASA5Ic6uQ8Wdjo08574apCd5tYFc1Q4DlZmSgCty0iyjNxxaIs0yk9E4o44tT2qtWWckJ9hqdwBQJ97+fW0bpCIxLtbtqJQODdO9Pqm5IiK2g6ZR3Tq2US4dG6Wjbp14NK3nPr96TbMMp5q+K2lJ8chtmWlrDaUnxdv1bbTOTkXz+sl2raVA8p7NMpMNTzzXta2unTuOwEqMi8U1zTI87isdG6WjRf0Up+3dtF6y3bj4+NgYuxalO9e1qW49OXKVK9bLSU+0tfoaaLXuqx3el5oYZ6vFexIfG2OXa6+XkmBXQ6+jpXl6GLRUOzZKd99Egv2+Z2VNKybExdjSTY7zJcXH2vp0rMdAZkqCV31FAOz2aaNtWNNMXXMPlRq6mtgrjw9sh8Edc1x2Goc7o7yooxXPD7Ad8OFswu+uRac/z3M7z9rRg/BzpedaajCNG3YtDp+5YJjienxgO7yzYI/L9y57bgDq1onHZaVQWnEJzTKTMfvxPh475/NGD/L7uEhLisePT/V13cGqDB+69emDPXD8XLmfJfKOF4PRahSDexCFemMCltqYUWDv2jwDBUfPO43ACDfetHo81fID4TiaJBDuctW2z6vlpjoA1EmINewcBTyvf31t3Nr68qYi4ZhG9NUVXrRKxMVjI6mJcUj1siUYqRjca0ANjWwKyF9u74zf9mjh00VfoZAQF4O5T16PIe8sr/XPXvxsf2R4eQuA2hAOlQWKXKbIubfLsZyBvc2F1ZRQXWGoHx3iSmJcbK2narzJ3xrp0NC3KwiDpVVWit0Vr76w5tyv9PM7hxPHC7rCXVvt+G+UkWS7QKmm+r18YU0dhuqmbaaouf+hbxv0aJXp9yXUweZN3tgXy0cOQJyLi3l+fKovcoI0MieY5j55vVcjN1xZ++IglFXUbi46EI3q1sG3f+ztVfrAW6GqLCx8pj9OlXk30iUc6I//q5tmoOhkmdNFaKFQNzkesx/v4/VAgGAzRXCPiZGwCOzWK/OuCfKZupmbK/WCGUyCKdDad4O0JCA8v5pLVzU1x211M1MS/L6/Uijoj/+UxDjDC9NCJZQDG0wR3MNFfGwMvvtjH7TMqrkOP4oezLlTIBjcg8wMOVcKDwzuFAhTdKgSmRFjOwWCwZ2IyIQY3ImITMjv4C4izURksYjsEJHtIvKENj1TROaLyB7tf2h/yocoQhnd4ZDIW4HU3C8BeEYp1QlATwCPiUgnAKMALFRKtQOwUHtORES1yO/grpQ6opTaoD0+D2AngCYAhgKYos02BcAdgRaSKBpF0lhzCj9BybmLSEsAXQHkAchRSh3RXjoKwPCXokXkIRHJF5H8khLjXxoiilYf3NsNAzvU7C/1kLkFHNxFJBXADABPKqXO6V9TlqShYeJQKfWhUipXKZWbnZ0daDGITOWmzg1r7Lc1KToEFNxFJB6WwP6ZUmqmNvmYiDTSXm8E4HhgRSQiIl8FMlpGAEwCsFMp9Q/dS98CGK49Hg5glv/FIyIifwRy+4HeAO4FsFVENmnTRgMYC2CaiIwAcADAbwIrIhER+crv4K6UWgHXP3gyyN/lEhFR4HiFKhGRCTG4ExGZEIM7EZEJMbgTEZkQgzsRkQkxuBMRmRCDOxGRCTG4ExGZEH8gm6gGfTqiB1KTvD/MProvF80zk2uwRBQtGNyJalCfdlk+zX9DJ8M7ZBP5jGkZIiITYnAnIjIhBnciIhNicCciMiEGdyIiE2JwJyIyIQZ3IiITYnAnIjIhBnciIhNicCciMiHefoBsXr6tE3q0qh/qYhBREDC4k839vVuFughEFCRMyxARmRCDOxGRCTG4ExGZEIM7EZEJMbgTEZkQgzsRkQkxuBMRmRCDOxGRCYlSKtRlgIiUADjg59uzAJwIYnHMgOvEGdeJM64Te5G4PloopbKNXgiL4B4IEclXSuWGuhzhhOvEGdeJM64Te2ZbH0zLEBGZEIM7EZEJmSG4fxjqAoQhrhNnXCfOuE7smWp9RHzOnYiInJmh5k5ERA4Y3ImITCiig7uIDBGRXSJSKCKjQl2eYBKRZiKyWER2iMh2EXlCm54pIvNFZI/2v542XUTkPW1dbBGRa3XLGq7Nv0dEhuumdxORrdp73hMRqf1v6jsRiRWRjSIyW3veSkTytO/xpYgkaNMTteeF2ustdct4QZu+S0Ru0k2PuH1KRDJEZLqIFIjIThHpFc37iYg8pR0z20TkcxFJisp9RCkVkX8AYgHsBdAaQAKAzQA6hbpcQfx+jQBcqz1OA7AbQCcAbwAYpU0fBeB17fEtAOYAEAA9AeRp0zMB7NP+19Me19NeW6vNK9p7bw719/Zy3TwNYCqA2drzaQDu1h5PAPCI9vhRABO0x3cD+FJ73EnbXxIBtNL2o9hI3acATAHwoPY4AUBGtO4nAJoA2A+gjm7f+H007iORXHPvDqBQKbVPKXURwBcAhoa4TEGjlDqilNqgPT4PYCcsO+5QWA5maP/v0B4PBfCJslgDIENEGgG4CcB8pdQppdRpAPMBDNFeS1dKrVGWvfkT3bLClog0BXArgInacwEwEMB0bRbHdWJdV9MBDNLmHwrgC6VUhVJqP4BCWPaniNunRKQugL4AJgGAUuqiUuoMons/iQNQR0TiACQDOIIo3EciObg3AXBI97xYm2Y6WlOxK4A8ADlKqSPaS0cB5GiPXa0Pd9OLDaaHu3cAjARwWXteH8AZpdQl7bn+e9i+u/b6WW1+X9dVOGsFoATAx1qqaqKIpCBK9xOl1GEAbwE4CEtQPwtgPaJwH4nk4B4VRCQVwAwATyqlzulf02pSUTOWVUR+CeC4Ump9qMsSRuIAXAtgvFKqK4AyWNIwNtG0n2h9C0NhOek1BpACYEhICxUikRzcDwNopnveVJtmGiISD0tg/0wpNVObfExrKkP7f1yb7mp9uJve1GB6OOsN4HYRKYKlOTwQwLuwpBbitHn038P23bXX6wI4Cd/XVTgrBlCslMrTnk+HJdhH634yGMB+pVSJUqoSwExY9puo20ciObivA9BO6wVPgKUz5NsQlylotLzfJAA7lVL/0L30LQDrSIbhAGbppt+njYboCeCs1iyfB+BGEamn1WpuBDBPe+2ciPTUPus+3bLCklLqBaVUU6VUS1i29yKl1G8BLAZwlzab4zqxrqu7tPmVNv1ubaREKwDtYOk0jLh9Sil1FMAhEWmvTRoEYAeidz85CKCniCRr5bWuj+jbR0LdoxvIHyw9/7th6b1+MdTlCfJ36wNLU3oLgE3a3y2w5AMXAtgDYAGATG1+ATBOWxdbAeTqlvUALB1ChQDu103PBbBNe8/70K5YjoQ/AP1RPVqmNSwHXiGArwAkatOTtOeF2uutde9/Ufveu6Ab/RGJ+xSAawDka/vKN7CMdona/QTAKwAKtDL/B5YRL1G3j/D2A0REJhTJaRkiInKBwZ2IyIQY3ImITIjBnYjIhBjciYhMiMGdiMiEGNyJiEzo/wF+DvqWCMvM6AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIoYX8Evn84K"
      },
      "source": [
        "# 6. Create Poem Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kv_CQy8n-zp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ff62ff2-3e99-478c-c93f-d400168fa627"
      },
      "source": [
        "configuration = GPT2Config(vocab_size=len(word_tokenizer), n_positions=max_len, n_embd=total_embed_dim)\n",
        "model = GPT2LMHeadModel(config=configuration)\n",
        "print(model)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPT2LMHeadModel(\n",
            "  (transformer): GPT2Model(\n",
            "    (wte): Embedding(30003, 576)\n",
            "    (wpe): Embedding(60, 576)\n",
            "    (drop): Dropout(p=0.1, inplace=False)\n",
            "    (h): ModuleList(\n",
            "      (0): GPT2Block(\n",
            "        (ln_1): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (1): GPT2Block(\n",
            "        (ln_1): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (2): GPT2Block(\n",
            "        (ln_1): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (3): GPT2Block(\n",
            "        (ln_1): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (4): GPT2Block(\n",
            "        (ln_1): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (5): GPT2Block(\n",
            "        (ln_1): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (6): GPT2Block(\n",
            "        (ln_1): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (7): GPT2Block(\n",
            "        (ln_1): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (8): GPT2Block(\n",
            "        (ln_1): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (9): GPT2Block(\n",
            "        (ln_1): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (10): GPT2Block(\n",
            "        (ln_1): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (11): GPT2Block(\n",
            "        (ln_1): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ln_f): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (lm_head): Linear(in_features=576, out_features=30003, bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ckesl5DqFarE"
      },
      "source": [
        "## 6.1 Sylliabification Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcZzh3dSFZ0e"
      },
      "source": [
        "class translater():\n",
        "  def __init__(self, word_tokenizer, syl_tokenizer):\n",
        "    self.word_tokenizer = word_tokenizer\n",
        "    self.syl_tokenizer = syl_tokenizer\n",
        "\n",
        "  def word_to_syl(self, x):\n",
        "    \n",
        "    \"\"\" \n",
        "    Convert word(tokenizer) to syllable(tokenizer) list  \n",
        "    args:\n",
        "      x : interger tokenzier \n",
        "    return:\n",
        "      syl_list : list of syllable tokenizer\n",
        "    \"\"\"\n",
        "    input_id = torch.tensor([x])\n",
        "    word = word_tokenizer.decode(input_id)\n",
        "    syllable_list = SonoriPy(word)  # a list of syllables\n",
        "    result = [self.syl_tokenizer.encode(i)[1] for i in syllable_list]\n",
        "    result = [i for i in result if i]\n",
        "    return result"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNPMQiSsGcT3"
      },
      "source": [
        "class syl_embedding(nn.Module):\n",
        "  def __init__(self, vocab_size, syl_size, syl_embed_len, word_embed_dim, word_to_syl, syl_embed_dim):\n",
        "    super(syl_embedding, self).__init__()\n",
        "    self.vocab_size = vocab_size\n",
        "    self.word_embed_dim = word_embed_dim\n",
        "    self.syl_embed_dim = syl_embed_dim\n",
        "    self.syl_embed_len = syl_embed_len\n",
        "    self.word_embedding = nn.Embedding(vocab_size, word_embed_dim)\n",
        "    self.syl_embedding  = nn.Embedding(syl_size, syl_embed_dim)\n",
        "    self.word_to_syl = word_to_syl\n",
        "  def forward(self, x):\n",
        "    word_embedding = self.word_embedding(x)\n",
        "    syl_embedding = torch.zeros(word_embedding.shape[0], word_embedding.shape[1], self.syl_embed_len*self.syl_embed_dim)\n",
        "    # print(syl_embedding.shape)\n",
        "\n",
        "    for i in range(x.shape[0]):\n",
        "      for j in range(x.shape[1]):\n",
        "        syls = self.word_to_syl(x[i, j])\n",
        "        syl_len = min(len(syls), self.syl_embed_len)\n",
        "\n",
        "        # if it is special token\n",
        "        # if(x[i, j] >= 30000 or x[i, j] <= 3):\n",
        "        #   syl_embedding[i, j] = torch.zeros(self.syl_embed_dim * self.syl_embed_len)\n",
        "        #   continue\n",
        "        # not a special token \n",
        "        for k in range(syl_len):\n",
        "          syl = syls[k]\n",
        "          syl = torch.tensor(syl).to(device)\n",
        "          syl_embedding[i, j, (self.syl_embed_len-syl_len+k) * self.syl_embed_dim : (self.syl_embed_len-syl_len+k+1)*self.syl_embed_dim] = self.syl_embedding(syl)\n",
        "\n",
        "    syl_embedding = syl_embedding.to(device)\n",
        "    final_embed = torch.cat((word_embedding, syl_embedding), dim=2)\n",
        "    return final_embed "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpFzFUMZo-oS"
      },
      "source": [
        "## 6.2 Modify gpt2 architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gM_r1nfNpHes"
      },
      "source": [
        "trans = translater(word_tokenizer, syl_tokenizer)\n",
        "syl_embed = syl_embedding(len(word_tokenizer), len(syl_tokenizer), 5, word_embed_dim=word_embed_dim, word_to_syl = trans.word_to_syl, syl_embed_dim=syl_embed_dim)\n",
        "model.transformer.wte = syl_embed\n",
        "# print(model)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8lFLJIBx2Ev"
      },
      "source": [
        "# 6.3 Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRfshf9Lx62H",
        "outputId": "40f9b736-0276-47b7-c854-6098bd57d56d"
      },
      "source": [
        "# model.cuda()\n",
        "optimizer = AdamW(model.parameters(), lr=learning_rate, eps=eps)\n",
        "total_steps = len(poem_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps=50,\n",
        "                                            num_training_steps=total_steps)\n",
        "start_time = time.time()\n",
        "model = model.to(device)\n",
        "for epoch_i in range(epochs):\n",
        "\n",
        "    print(f'Epoch {epoch_i + 1} of {epochs}')\n",
        "\n",
        "    t0 = time.time()\n",
        "    total_train_loss = 0\n",
        "    model.train()\n",
        "\n",
        "    for batch in tqdm(poem_dataloader):\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[0].to(device)\n",
        "        b_masks = batch[1].to(device)\n",
        "\n",
        "        model.zero_grad()        \n",
        "\n",
        "        outputs = model(b_input_ids,\n",
        "                        labels=b_labels,\n",
        "                        attention_mask=b_masks,\n",
        "                        token_type_ids=None)\n",
        "\n",
        "        loss = outputs[0]  \n",
        "\n",
        "        batch_loss = loss.item()\n",
        "        total_train_loss += batch_loss\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(poem_dataloader)       \n",
        "    training_time = (time.time() - t0)\n",
        "    torch.save(model.state_dict(), '/content/drive/MyDrive/11785/project/modelll.pth')\n",
        "    print(f'Average Training Loss: {avg_train_loss}. Epoch Training Time: {training_time}. Learning rate: {optimizer.param_groups[0][\"lr\"]}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 of 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 13%|█▎        | 739/5532 [08:53<57:33,  1.39it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHKDEsz9x0Xb",
        "outputId": "f9a24dd8-b3d6-4a38-89cc-384218204f90"
      },
      "source": [
        "state_dict = torch.load('/content/drive/MyDrive/11785/project/modelll.pth')\n",
        "model.load_state_dict(state_dict)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "Pa-tGRzzeKGu",
        "outputId": "6678ae0a-214e-4fc6-e630-4e4d2891779b"
      },
      "source": [
        "optimizer.param_groups[0][\"lr\"]"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-c83602cb74cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lr\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'optimizer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVZO24RnoC0T"
      },
      "source": [
        "# 7. Generate Poem Stanzas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "pD8kzqutsIid",
        "outputId": "1ed44e6e-f776-4013-9856-cc8f43f82362"
      },
      "source": [
        ""
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-78-18bf08814031>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/cuda/memory.py\u001b[0m in \u001b[0;36mempty_cache\u001b[0;34m()\u001b[0m\n\u001b[1;32m    112\u001b[0m     \"\"\"\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_emptyCache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fm0xphgtoGgZ",
        "outputId": "6fbc5431-6431-4ad6-f480-4c184af65223"
      },
      "source": [
        "prompt = \"[CLS]\"\n",
        "generated = torch.tensor(word_tokenizer.encode(prompt)).unsqueeze(0)\n",
        "generated = generated.to(device)\n",
        "model.cuda()\n",
        "model.eval()\n",
        "sample_outputs = model.generate(\n",
        "                                generated, \n",
        "                                do_sample=True,   \n",
        "                                top_k=30, \n",
        "                                max_length=60,\n",
        "                                top_p=0.92, \n",
        "                                num_return_sequences=3)\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "    print(\"{}: {}\\n\\n\".format(i, word_tokenizer.decode(sample_output, skip_special_tokens=True)))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: thats a small bird whos a whiz - of his life and his body is odd - as a bird you have heard - the name in the main kind - and thats true it can make you seem grand\n",
            "\n",
            "\n",
            "1: ##s a new dress on this boat is the main - and its name is now used as a joke - its a way to get laid - to define and get laid - of this word for a treat - when it comes and youd need to a lot more to a week\n",
            "\n",
            "\n",
            "2: and quite an old way out of strife - the name that he used in a wife of the strife - was the best that his brother - with the guy was the story - so she left her in his life as a fool\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXtTWlcjr9rW",
        "outputId": "b0739036-1dd1-4293-a9a0-c63ad43689fe"
      },
      "source": [
        "SonoriPy('rigid')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['ri', 'gid']"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jj_OQlLrwxEh"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "oiLXn7u9x4TJ",
        "outputId": "3d5c8c61-fe18-4801-d06c-978f6c71fd87"
      },
      "source": [
        "word_tokenizer.decode(torch.tensor([1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'-'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjUD22WltE6D",
        "outputId": "304b1887-03e4-401b-973b-1bcd8885d947"
      },
      "source": [
        "trans.word_to_syl(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "VC0JlwQCotQN",
        "outputId": "9efcc5d3-030b-4103-c485-84f34fdb2e11"
      },
      "source": [
        "# syl_embed = syl_embed.to(device)\n",
        "model = model.to(device)\n",
        "for batch in tqdm(poem_dataloader):\n",
        "  b_input_ids = batch\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/2766 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32, 120, 320])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 1/2766 [00:00<43:15,  1.07it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32, 120, 320])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 2/2766 [00:01<44:24,  1.04it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32, 120, 320])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 3/2766 [00:02<44:47,  1.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32, 120, 320])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 4/2766 [00:03<44:26,  1.04it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32, 120, 320])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 5/2766 [00:04<44:47,  1.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32, 120, 320])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 6/2766 [00:05<44:38,  1.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32, 120, 320])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 7/2766 [00:06<45:43,  1.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32, 120, 320])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 8/2766 [00:07<45:02,  1.02it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32, 120, 320])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 9/2766 [00:08<45:13,  1.02it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32, 120, 320])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 10/2766 [00:09<45:07,  1.02it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32, 120, 320])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 11/2766 [00:10<44:32,  1.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32, 120, 320])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 12/2766 [00:11<44:25,  1.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32, 120, 320])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 13/2766 [00:12<45:18,  1.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32, 120, 320])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 14/2766 [00:13<45:38,  1.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32, 120, 320])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 15/2766 [00:14<45:34,  1.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32, 120, 320])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  1%|          | 16/2766 [00:15<45:08,  1.02it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-f6f86a2c043f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# syl_embed = syl_embed.to(device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoem_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mb_input_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mb_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-eeb898a26368>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     14\u001b[0m                                         \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                                         \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                                         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'max_length'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m                                         )\n\u001b[1;32m     18\u001b[0m         \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencodings_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2440\u001b[0m                 \u001b[0mreturn_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2441\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2442\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2443\u001b[0m             )\n\u001b[1;32m   2444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mencode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2510\u001b[0m             \u001b[0mreturn_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2511\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2512\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2513\u001b[0m         )\n\u001b[1;32m   2514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36m_encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    630\u001b[0m             )\n\u001b[1;32m    631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 632\u001b[0;31m         \u001b[0mfirst_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    633\u001b[0m         \u001b[0msecond_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtext_pair\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36mget_input_ids\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m                 \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    602\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_tokens_to_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m                 \u001b[0mtokenized_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m                 \u001b[0mtokenized_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;31m# [\"This\", \" is\", \" something\", \"<special_token_1>\", \"else\"]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtokenized_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/tokenization_bert.py\u001b[0m in \u001b[0;36m_tokenize\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0msplit_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_basic_tokenize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnever_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_special_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                 \u001b[0;31m# If the token is part of the never_split set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/tokenization_bert.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, never_split)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;31m# words in the English Wikipedia.).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize_chinese_chars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokenize_chinese_chars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m         \u001b[0morig_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwhitespace_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[0msplit_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/tokenization_bert.py\u001b[0m in \u001b[0;36m_tokenize_chinese_chars\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mchar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m             \u001b[0mcp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_chinese_char\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m                 \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDTSq-pCtAsU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}