{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pr-type-id.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c18eba9ec3594af79cb9278a45b37716": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e1a0fbd387e04392913a9e7a1f819bf2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_aebce9e2218549b28da292b9e0be6fc0",
              "IPY_MODEL_7745cd0e139c48308345165bc958fed3",
              "IPY_MODEL_3b6c487602604e66b2105e7382702176"
            ]
          }
        },
        "e1a0fbd387e04392913a9e7a1f819bf2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aebce9e2218549b28da292b9e0be6fc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b2b665d1f13e47939ea2c2a4cce816ca",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0a07396c51d04617a660746d5833d9b9"
          }
        },
        "7745cd0e139c48308345165bc958fed3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d8a986951461438da5cde657ca00101d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1042301,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1042301,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_abe8245c6f654f2c9fab32086c352bea"
          }
        },
        "3b6c487602604e66b2105e7382702176": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3236249a91ee4675be6182f9986c4e27",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.99M/0.99M [00:00&lt;00:00, 2.65MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_db722dd8dfdd4d4c9fdbc4405aa99ff3"
          }
        },
        "b2b665d1f13e47939ea2c2a4cce816ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0a07396c51d04617a660746d5833d9b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d8a986951461438da5cde657ca00101d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "abe8245c6f654f2c9fab32086c352bea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3236249a91ee4675be6182f9986c4e27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "db722dd8dfdd4d4c9fdbc4405aa99ff3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f182faf32f6c4fa9af1eacd46f87cbce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c15bb8d570e04e9e9220f4d4fc894e22",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_11e7511ffb03421289efea987aa49729",
              "IPY_MODEL_0a69bcff12d7421fbc0efe65830c5f88",
              "IPY_MODEL_ecec65ca0a74405ca94890817b20a273"
            ]
          }
        },
        "c15bb8d570e04e9e9220f4d4fc894e22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "11e7511ffb03421289efea987aa49729": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_79cc9158720b4757b0f59092d566e44c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_696d8ee15d0347219bc2f2d0c3d1155a"
          }
        },
        "0a69bcff12d7421fbc0efe65830c5f88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_43de6c0f65d647e3b7da8a3727f8314e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2f53fa9f61b242cbbae29e8e1e614651"
          }
        },
        "ecec65ca0a74405ca94890817b20a273": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e32fc99e2ef3422194aa43e8f8a17ed5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 446k/446k [00:00&lt;00:00, 858kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eb72792c857142af8cac11e833333658"
          }
        },
        "79cc9158720b4757b0f59092d566e44c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "696d8ee15d0347219bc2f2d0c3d1155a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "43de6c0f65d647e3b7da8a3727f8314e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2f53fa9f61b242cbbae29e8e1e614651": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e32fc99e2ef3422194aa43e8f8a17ed5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eb72792c857142af8cac11e833333658": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d48cb42e67384e048dfc4f23b0877368": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_eb90bced1b6b41e5957f11d83393a993",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5785373b812e47efb31c68d9ecb56b56",
              "IPY_MODEL_5dfcbf207aa94331a8fc9f32270a3ac7",
              "IPY_MODEL_0c8c84cb7bf54ae89ab5c24a02b4aeab"
            ]
          }
        },
        "eb90bced1b6b41e5957f11d83393a993": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5785373b812e47efb31c68d9ecb56b56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_85788a1652ff48cb813cd4486d004491",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8653a1d9b9f34e53a11c34170456d76a"
          }
        },
        "5dfcbf207aa94331a8fc9f32270a3ac7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e8b9b9ef173a423685f882ffcb40ec4a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1355256,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1355256,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6b52a8b9bbae448d9511d617511bd272"
          }
        },
        "0c8c84cb7bf54ae89ab5c24a02b4aeab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_26616f8ee65b4c5ba139370fb38e3eab",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.29M/1.29M [00:00&lt;00:00, 2.25MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_41ac1842c4c5419f80ddab6f4ea2ee9e"
          }
        },
        "85788a1652ff48cb813cd4486d004491": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8653a1d9b9f34e53a11c34170456d76a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e8b9b9ef173a423685f882ffcb40ec4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6b52a8b9bbae448d9511d617511bd272": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "26616f8ee65b4c5ba139370fb38e3eab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "41ac1842c4c5419f80ddab6f4ea2ee9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "67461cb30e184d26881164ac823529af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_79203d773f3942c0b37a38cfe9e472a7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3a7ab6d927c444be93401bff8db4e1cc",
              "IPY_MODEL_56b6052be5904862a6fecc53e659c034",
              "IPY_MODEL_ecd35cb4880d461d9996a7d59fb2f62d"
            ]
          }
        },
        "79203d773f3942c0b37a38cfe9e472a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3a7ab6d927c444be93401bff8db4e1cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0c272afc029449e98170debcba45d1ed",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_42999472938a420c9106a893a17f5fab"
          }
        },
        "56b6052be5904862a6fecc53e659c034": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_38bbee53c63843bea226f92ae96176b7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 665,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 665,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9d88120aeec54d8984cdc769274ee565"
          }
        },
        "ecd35cb4880d461d9996a7d59fb2f62d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_56f2fb1fbd724536abc1056b2b75bf27",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 665/665 [00:00&lt;00:00, 14.1kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_addb6172c76d41148be9c970f9b71d28"
          }
        },
        "0c272afc029449e98170debcba45d1ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "42999472938a420c9106a893a17f5fab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "38bbee53c63843bea226f92ae96176b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9d88120aeec54d8984cdc769274ee565": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "56f2fb1fbd724536abc1056b2b75bf27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "addb6172c76d41148be9c970f9b71d28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c1e3d9f058d84ff5871b1dedb7b830d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f8ddba81585d407ab2cec0b1e736bbd4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_76e3cc498e0b4d4a9b13c95b6922bf7e",
              "IPY_MODEL_848ca6841a3e45e1af2c0ae74fadd731",
              "IPY_MODEL_9cfab8c2c3924968b9b1b47c3ba5dc24"
            ]
          }
        },
        "f8ddba81585d407ab2cec0b1e736bbd4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "76e3cc498e0b4d4a9b13c95b6922bf7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_27bb13d4f2a8443398037d497c5cd683",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3230626405264061ac5dd0aea6006d1d"
          }
        },
        "848ca6841a3e45e1af2c0ae74fadd731": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5973aa2e0a654d8e92ab5094751ef02c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 665,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 665,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_86146e58b158477f98440292d68fa0d1"
          }
        },
        "9cfab8c2c3924968b9b1b47c3ba5dc24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5db1c9fb01214fe7898ec726c1bebd2a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 665/665 [00:00&lt;00:00, 24.4kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_480149419b9941f797b24ac11abdbd63"
          }
        },
        "27bb13d4f2a8443398037d497c5cd683": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3230626405264061ac5dd0aea6006d1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5973aa2e0a654d8e92ab5094751ef02c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "86146e58b158477f98440292d68fa0d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5db1c9fb01214fe7898ec726c1bebd2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "480149419b9941f797b24ac11abdbd63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1d2adaac34694034a5018877f795dd49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8f67a82b37d8428195d489032f2163d1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0fab5e00f9a1440facf2509f723e188e",
              "IPY_MODEL_c0f533a91ccb49378e8a2377b2a03200",
              "IPY_MODEL_89a0cc7251f1456c96975611799d2eed"
            ]
          }
        },
        "8f67a82b37d8428195d489032f2163d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0fab5e00f9a1440facf2509f723e188e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_35a1404b91ca46ffad4000e6daca1f90",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e0fdf0ae4079484ea1c40f76d80d9469"
          }
        },
        "c0f533a91ccb49378e8a2377b2a03200": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_adffb1973ded4381a620982c5ec25c97",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 548118077,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 548118077,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0e187dc320574ce9b339fc6447fa6b1a"
          }
        },
        "89a0cc7251f1456c96975611799d2eed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_000e80c4c4454cb9a5b33afdfbceba4f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 523M/523M [00:09&lt;00:00, 63.6MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bfb6efc8bb91453ea3d2bceb7f7be7e3"
          }
        },
        "35a1404b91ca46ffad4000e6daca1f90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e0fdf0ae4079484ea1c40f76d80d9469": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "adffb1973ded4381a620982c5ec25c97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0e187dc320574ce9b339fc6447fa6b1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "000e80c4c4454cb9a5b33afdfbceba4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bfb6efc8bb91453ea3d2bceb7f7be7e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mCYlorBs4hi"
      },
      "source": [
        "# Jinchi's runable train ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmqdeJFVZZWZ",
        "outputId": "f8a05ac4-b588-4669-bcb4-583fb70b60a7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6UZfKK12Fl0T",
        "outputId": "80ad191d-fa02-47c4-ebe9-67ed756850ed"
      },
      "source": [
        "!git clone https://github.com/huggingface/transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'transformers'...\n",
            "remote: Enumerating objects: 90172, done.\u001b[K\n",
            "remote: Total 90172 (delta 0), reused 0 (delta 0), pack-reused 90172\u001b[K\n",
            "Receiving objects: 100% (90172/90172), 73.80 MiB | 14.37 MiB/s, done.\n",
            "Resolving deltas: 100% (64984/64984), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-jEkQxZFlxr",
        "outputId": "f38a3149-3d7a-47a4-dcc8-2eafbe1d6aa0"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.12.5-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 4.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.1.2-py3-none-any.whl (59 kB)\n",
            "\u001b[K     |████████████████████████████████| 59 kB 8.8 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 77.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 75.1 MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 60.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.1.2 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.12.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kd50vxTLFlu6",
        "outputId": "88ca289c-631a-4334-853d-3300ba01100f"
      },
      "source": [
        "import os\n",
        "os.chdir(\"transformers\")\n",
        "os.chdir(\"./examples/pytorch/language-modeling\")\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "README.md\t  run_clm_no_trainer.py  run_mlm_no_trainer.py\trun_plm.py\n",
            "requirements.txt  run_clm.py\t\t run_mlm.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Du8Hsr8FlsA",
        "outputId": "49193d79-f266-469b-db9e-bf14411e2911"
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting accelerate\n",
            "  Downloading accelerate-0.5.1-py3-none-any.whl (58 kB)\n",
            "\u001b[?25l\r\u001b[K     |█████▋                          | 10 kB 42.8 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 20 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 30 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 40 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 51 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 58 kB 2.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (1.10.0+cu111)\n",
            "Collecting datasets>=1.8.0\n",
            "  Downloading datasets-1.16.0-py3-none-any.whl (298 kB)\n",
            "\u001b[K     |████████████████████████████████| 298 kB 8.6 MB/s \n",
            "\u001b[?25hCollecting sentencepiece!=0.1.92\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 81.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (3.17.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3->-r requirements.txt (line 2)) (3.10.0.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r requirements.txt (line 3)) (0.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r requirements.txt (line 3)) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r requirements.txt (line 3)) (4.8.2)\n",
            "Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r requirements.txt (line 3)) (3.0.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r requirements.txt (line 3)) (1.19.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r requirements.txt (line 3)) (1.1.5)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r requirements.txt (line 3)) (0.3.4)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r requirements.txt (line 3)) (0.70.12.2)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r requirements.txt (line 3)) (4.62.3)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 63.4 MB/s \n",
            "\u001b[?25hCollecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2021.11.0-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 85.6 MB/s \n",
            "\u001b[?25hCollecting xxhash\n",
            "  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n",
            "\u001b[K     |████████████████████████████████| 243 kB 86.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r requirements.txt (line 3)) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets>=1.8.0->-r requirements.txt (line 3)) (3.4.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets>=1.8.0->-r requirements.txt (line 3)) (6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets>=1.8.0->-r requirements.txt (line 3)) (3.0.6)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets>=1.8.0->-r requirements.txt (line 3)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets>=1.8.0->-r requirements.txt (line 3)) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets>=1.8.0->-r requirements.txt (line 3)) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets>=1.8.0->-r requirements.txt (line 3)) (3.0.4)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->-r requirements.txt (line 5)) (1.15.0)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.1-py3-none-any.whl (5.7 kB)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-5.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n",
            "\u001b[K     |████████████████████████████████| 160 kB 77.2 MB/s \n",
            "\u001b[?25hCollecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=1.8.0->-r requirements.txt (line 3)) (2.0.7)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 75.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=1.8.0->-r requirements.txt (line 3)) (21.2.0)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (192 kB)\n",
            "\u001b[K     |████████████████████████████████| 192 kB 76.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets>=1.8.0->-r requirements.txt (line 3)) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets>=1.8.0->-r requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets>=1.8.0->-r requirements.txt (line 3)) (2018.9)\n",
            "Installing collected packages: multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, fsspec, aiohttp, xxhash, sentencepiece, datasets, accelerate\n",
            "Successfully installed accelerate-0.5.1 aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.1 asynctest-0.13.0 datasets-1.16.0 frozenlist-1.2.0 fsspec-2021.11.0 multidict-5.2.0 sentencepiece-0.1.96 xxhash-2.0.2 yarl-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eq52j6frFlox",
        "outputId": "31ec5001-0095-456d-89ab-17b0ff05845f"
      },
      "source": [
        "!pip install pyarrow --upgrade"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.7/dist-packages (3.0.0)\n",
            "Collecting pyarrow\n",
            "  Downloading pyarrow-6.0.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.6 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from pyarrow) (1.19.5)\n",
            "Installing collected packages: pyarrow\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 3.0.0\n",
            "    Uninstalling pyarrow-3.0.0:\n",
            "      Successfully uninstalled pyarrow-3.0.0\n",
            "Successfully installed pyarrow-6.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAVyQqMAFllI",
        "outputId": "b85caa73-c301-4e00-e3e9-0029bfc4e79c"
      },
      "source": [
        "! pip install git+git://github.com/huggingface/transformers/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+git://github.com/huggingface/transformers/\n",
            "  Cloning git://github.com/huggingface/transformers/ to /tmp/pip-req-build-k018jkg1\n",
            "  Running command git clone -q git://github.com/huggingface/transformers/ /tmp/pip-req-build-k018jkg1\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (4.62.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (6.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (0.10.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (0.0.46)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (0.1.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (4.8.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (3.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.13.0.dev0) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.13.0.dev0) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.13.0.dev0) (3.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.13.0.dev0) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.13.0.dev0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.13.0.dev0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.13.0.dev0) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.13.0.dev0) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.13.0.dev0) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.13.0.dev0) (1.15.0)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.13.0.dev0-py3-none-any.whl size=3178126 sha256=76007081de95c1fb907f542be489858848adf559798212f40449d5ebd586a091\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-gvw0hddv/wheels/f4/91/48/ae60caddf7ba98e63091b5875e89c981881eb4c7fc334f08a2\n",
            "Successfully built transformers\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.12.5\n",
            "    Uninstalling transformers-4.12.5:\n",
            "      Successfully uninstalled transformers-4.12.5\n",
            "Successfully installed transformers-4.13.0.dev0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sgUT1ifFld0",
        "outputId": "495d10f4-8463-4380-dfca-e3ead6e97cee"
      },
      "source": [
        "!pwd\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/transformers/examples/pytorch/language-modeling\n",
            "README.md\t  run_clm_no_trainer.py  run_mlm_no_trainer.py\trun_plm.py\n",
            "requirements.txt  run_clm.py\t\t run_mlm.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahDOJgvLF7Mt",
        "outputId": "4e6920c3-4739-42cc-d5ac-03bf1b2bf749"
      },
      "source": [
        "!python run_clm.py \\\n",
        "--model_type gpt2-medium \\\n",
        "--model_name_or_path gpt2-medium \\\n",
        "--train_file \"/content/gdrive/MyDrive/pr/limericks_input.txt\" \\\n",
        "--do_train \\\n",
        "--per_device_train_batch_size 1 \\\n",
        "--save_steps 500 \\\n",
        "--num_train_epochs 5 \\\n",
        "--output_dir=\"/content/gdrive/MyDrive/pr/output\" \\\n",
        "--overwrite_output_dir \\\n",
        "--tokenizer_name /content/poem"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11/14/2021 15:53:35 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
            "11/14/2021 15:53:35 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_find_unused_parameters=None,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=False,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_steps=None,\n",
            "evaluation_strategy=IntervalStrategy.NO,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "hub_model_id=None,\n",
            "hub_strategy=HubStrategy.EVERY_SAVE,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=5e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=-1,\n",
            "log_level=-1,\n",
            "log_level_replica=-1,\n",
            "log_on_each_node=True,\n",
            "logging_dir=/content/gdrive/MyDrive/pr/output/runs/Nov14_15-53-35_9a4b6f54589c,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "lr_scheduler_type=SchedulerType.LINEAR,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=5.0,\n",
            "output_dir=/content/gdrive/MyDrive/pr/output,\n",
            "overwrite_output_dir=True,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=1,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=/content/gdrive/MyDrive/pr/output,\n",
            "save_on_each_node=False,\n",
            "save_steps=500,\n",
            "save_strategy=IntervalStrategy.STEPS,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_legacy_prediction_loop=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            "xpu_backend=None,\n",
            ")\n",
            "11/14/2021 15:53:35 - WARNING - datasets.builder - Using custom data configuration default-2439773f47298b3b\n",
            "11/14/2021 15:53:35 - INFO - datasets.builder - Generating dataset text (/root/.cache/huggingface/datasets/text/default-2439773f47298b3b/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5)\n",
            "Downloading and preparing dataset text/default to /root/.cache/huggingface/datasets/text/default-2439773f47298b3b/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5...\n",
            "100% 1/1 [00:00<00:00, 3269.14it/s]\n",
            "11/14/2021 15:53:35 - INFO - datasets.utils.download_manager - Downloading took 0.0 min\n",
            "11/14/2021 15:53:38 - INFO - datasets.utils.download_manager - Checksum Computation took 0.0 min\n",
            "100% 1/1 [00:00<00:00, 137.59it/s]\n",
            "11/14/2021 15:53:38 - INFO - datasets.utils.info_utils - Unable to verify checksums.\n",
            "11/14/2021 15:53:38 - INFO - datasets.builder - Generating split train\n",
            "11/14/2021 15:53:38 - INFO - datasets.utils.info_utils - Unable to verify splits sizes.\n",
            "Dataset text downloaded and prepared to /root/.cache/huggingface/datasets/text/default-2439773f47298b3b/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5. Subsequent calls will reuse this data.\n",
            "100% 1/1 [00:00<00:00, 210.19it/s]\n",
            "11/14/2021 15:53:39 - WARNING - datasets.builder - Using custom data configuration default-2439773f47298b3b\n",
            "11/14/2021 15:53:39 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
            "11/14/2021 15:53:39 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/text/default-2439773f47298b3b/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5\n",
            "11/14/2021 15:53:39 - WARNING - datasets.builder - Reusing dataset text (/root/.cache/huggingface/datasets/text/default-2439773f47298b3b/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5)\n",
            "11/14/2021 15:53:39 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/text/default-2439773f47298b3b/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5\n",
            "11/14/2021 15:53:40 - WARNING - datasets.builder - Using custom data configuration default-2439773f47298b3b\n",
            "11/14/2021 15:53:40 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
            "11/14/2021 15:53:40 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/text/default-2439773f47298b3b/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5\n",
            "11/14/2021 15:53:40 - WARNING - datasets.builder - Reusing dataset text (/root/.cache/huggingface/datasets/text/default-2439773f47298b3b/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5)\n",
            "11/14/2021 15:53:40 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/text/default-2439773f47298b3b/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5\n",
            "[INFO|file_utils.py:1753] 2021-11-14 15:53:40,989 >> https://huggingface.co/gpt2-medium/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpah_f8c83\n",
            "Downloading: 100% 718/718 [00:00<00:00, 726kB/s]\n",
            "[INFO|file_utils.py:1757] 2021-11-14 15:53:41,727 >> storing https://huggingface.co/gpt2-medium/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/3a7a4b7235202f93d14a4a5e8200709184c5b25a29d9cfa6b0ede5166adf0768.cf0ec4a33a38dc96108560e01338af4bd3360dd859385d451c35b41987ae73ff\n",
            "[INFO|file_utils.py:1765] 2021-11-14 15:53:41,727 >> creating metadata file for /root/.cache/huggingface/transformers/3a7a4b7235202f93d14a4a5e8200709184c5b25a29d9cfa6b0ede5166adf0768.cf0ec4a33a38dc96108560e01338af4bd3360dd859385d451c35b41987ae73ff\n",
            "[INFO|configuration_utils.py:588] 2021-11-14 15:53:41,727 >> loading configuration file https://huggingface.co/gpt2-medium/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3a7a4b7235202f93d14a4a5e8200709184c5b25a29d9cfa6b0ede5166adf0768.cf0ec4a33a38dc96108560e01338af4bd3360dd859385d451c35b41987ae73ff\n",
            "[INFO|configuration_utils.py:625] 2021-11-14 15:53:41,728 >> Model config GPT2Config {\n",
            "  \"_name_or_path\": \"gpt2-medium\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 1024,\n",
            "  \"n_head\": 16,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 24,\n",
            "  \"n_positions\": 1024,\n",
            "  \"n_special\": 0,\n",
            "  \"predict_special_tokens\": true,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.13.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "[INFO|tokenization_auto.py:343] 2021-11-14 15:53:41,728 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
            "[INFO|configuration_utils.py:586] 2021-11-14 15:53:41,728 >> loading configuration file /content/poem/config.json\n",
            "[INFO|configuration_utils.py:625] 2021-11-14 15:53:41,729 >> Model config GPT2Config {\n",
            "  \"_name_or_path\": \"/content/poem\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"transformers_version\": \"4.13.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:1671] 2021-11-14 15:53:41,730 >> Didn't find file /content/poem/tokenizer.json. We won't load it.\n",
            "[INFO|tokenization_utils_base.py:1671] 2021-11-14 15:53:41,730 >> Didn't find file /content/poem/added_tokens.json. We won't load it.\n",
            "[INFO|tokenization_utils_base.py:1671] 2021-11-14 15:53:41,730 >> Didn't find file /content/poem/special_tokens_map.json. We won't load it.\n",
            "[INFO|tokenization_utils_base.py:1671] 2021-11-14 15:53:41,730 >> Didn't find file /content/poem/tokenizer_config.json. We won't load it.\n",
            "[INFO|tokenization_utils_base.py:1740] 2021-11-14 15:53:41,730 >> loading file /content/poem/vocab.json\n",
            "[INFO|tokenization_utils_base.py:1740] 2021-11-14 15:53:41,730 >> loading file /content/poem/merges.txt\n",
            "[INFO|tokenization_utils_base.py:1740] 2021-11-14 15:53:41,730 >> loading file None\n",
            "[INFO|tokenization_utils_base.py:1740] 2021-11-14 15:53:41,730 >> loading file None\n",
            "[INFO|tokenization_utils_base.py:1740] 2021-11-14 15:53:41,730 >> loading file None\n",
            "[INFO|tokenization_utils_base.py:1740] 2021-11-14 15:53:41,730 >> loading file None\n",
            "[INFO|configuration_utils.py:586] 2021-11-14 15:53:41,730 >> loading configuration file /content/poem/config.json\n",
            "[INFO|configuration_utils.py:625] 2021-11-14 15:53:41,731 >> Model config GPT2Config {\n",
            "  \"_name_or_path\": \"/content/poem\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"transformers_version\": \"4.13.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "[INFO|configuration_utils.py:586] 2021-11-14 15:53:41,797 >> loading configuration file /content/poem/config.json\n",
            "[INFO|configuration_utils.py:625] 2021-11-14 15:53:41,797 >> Model config GPT2Config {\n",
            "  \"_name_or_path\": \"/content/poem\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"transformers_version\": \"4.13.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "[INFO|file_utils.py:1753] 2021-11-14 15:53:42,603 >> https://huggingface.co/gpt2-medium/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpqpj3cl0v\n",
            "Downloading: 100% 1.42G/1.42G [00:22<00:00, 68.1MB/s]\n",
            "[INFO|file_utils.py:1757] 2021-11-14 15:54:05,034 >> storing https://huggingface.co/gpt2-medium/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/6249eef5c8c1fcfccf9f36fc2e59301b109ac4036d8ebbee9c2b7f7e47f440bd.2538e2565f9e439a3668b981faf959c8b490b36dd631f3c4cd992519b2dd36f1\n",
            "[INFO|file_utils.py:1765] 2021-11-14 15:54:05,034 >> creating metadata file for /root/.cache/huggingface/transformers/6249eef5c8c1fcfccf9f36fc2e59301b109ac4036d8ebbee9c2b7f7e47f440bd.2538e2565f9e439a3668b981faf959c8b490b36dd631f3c4cd992519b2dd36f1\n",
            "[INFO|modeling_utils.py:1342] 2021-11-14 15:54:05,035 >> loading weights file https://huggingface.co/gpt2-medium/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/6249eef5c8c1fcfccf9f36fc2e59301b109ac4036d8ebbee9c2b7f7e47f440bd.2538e2565f9e439a3668b981faf959c8b490b36dd631f3c4cd992519b2dd36f1\n",
            "[INFO|modeling_utils.py:1609] 2021-11-14 15:54:09,072 >> All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "[INFO|modeling_utils.py:1618] 2021-11-14 15:54:09,072 >> All the weights of GPT2LMHeadModel were initialized from the model checkpoint at gpt2-medium.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
            "Running tokenizer on dataset:   0% 0/589 [00:00<?, ?ba/s]11/14/2021 15:54:09 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/text/default-2439773f47298b3b/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5/cache-98108a371ca47ee7.arrow\n",
            "Running tokenizer on dataset: 100% 589/589 [00:09<00:00, 58.90ba/s]\n",
            "Running tokenizer on dataset:   0% 0/31 [00:00<?, ?ba/s]11/14/2021 15:54:19 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/text/default-2439773f47298b3b/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5/cache-85da0dd5aa02c4fe.arrow\n",
            "Running tokenizer on dataset: 100% 31/31 [00:00<00:00, 60.70ba/s]\n",
            "11/14/2021 15:54:20 - WARNING - __main__ - The tokenizer picked seems to have a very large `model_max_length` (1000000000000000019884624838656). Picking 1024 instead. You can change that default value by passing --block_size xxx.\n",
            "Grouping texts in chunks of 1024:   0% 0/589 [00:00<?, ?ba/s]11/14/2021 15:54:20 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/text/default-2439773f47298b3b/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5/cache-3567b27d9b50a04d.arrow\n",
            "Grouping texts in chunks of 1024: 100% 589/589 [00:14<00:00, 41.82ba/s]\n",
            "Grouping texts in chunks of 1024:   0% 0/31 [00:00<?, ?ba/s]11/14/2021 15:54:34 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/text/default-2439773f47298b3b/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5/cache-4d48325eb1410ffb.arrow\n",
            "Grouping texts in chunks of 1024: 100% 31/31 [00:00<00:00, 42.27ba/s]\n",
            "[INFO|trainer.py:1196] 2021-11-14 15:54:47,721 >> ***** Running training *****\n",
            "[INFO|trainer.py:1197] 2021-11-14 15:54:47,721 >>   Num examples = 2943\n",
            "[INFO|trainer.py:1198] 2021-11-14 15:54:47,721 >>   Num Epochs = 5\n",
            "[INFO|trainer.py:1199] 2021-11-14 15:54:47,721 >>   Instantaneous batch size per device = 1\n",
            "[INFO|trainer.py:1200] 2021-11-14 15:54:47,721 >>   Total train batch size (w. parallel, distributed & accumulation) = 1\n",
            "[INFO|trainer.py:1201] 2021-11-14 15:54:47,721 >>   Gradient Accumulation steps = 1\n",
            "[INFO|trainer.py:1202] 2021-11-14 15:54:47,721 >>   Total optimization steps = 14715\n",
            "{'loss': 6.6811, 'learning_rate': 4.8301053346924904e-05, 'epoch': 0.17}\n",
            "  3% 500/14715 [04:57<2:21:48,  1.67it/s][INFO|trainer.py:1995] 2021-11-14 15:59:44,969 >> Saving model checkpoint to /content/gdrive/MyDrive/pr/output/checkpoint-500\n",
            "[INFO|configuration_utils.py:417] 2021-11-14 15:59:44,974 >> Configuration saved in /content/gdrive/MyDrive/pr/output/checkpoint-500/config.json\n",
            "[INFO|modeling_utils.py:1060] 2021-11-14 15:59:49,625 >> Model weights saved in /content/gdrive/MyDrive/pr/output/checkpoint-500/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2037] 2021-11-14 15:59:51,615 >> tokenizer config file saved in /content/gdrive/MyDrive/pr/output/checkpoint-500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2043] 2021-11-14 15:59:51,619 >> Special tokens file saved in /content/gdrive/MyDrive/pr/output/checkpoint-500/special_tokens_map.json\n",
            "{'loss': 6.0496, 'learning_rate': 4.660210669384982e-05, 'epoch': 0.34}\n",
            "  7% 1000/14715 [10:27<2:15:35,  1.69it/s][INFO|trainer.py:1995] 2021-11-14 16:05:15,551 >> Saving model checkpoint to /content/gdrive/MyDrive/pr/output/checkpoint-1000\n",
            "[INFO|configuration_utils.py:417] 2021-11-14 16:05:15,555 >> Configuration saved in /content/gdrive/MyDrive/pr/output/checkpoint-1000/config.json\n",
            "[INFO|modeling_utils.py:1060] 2021-11-14 16:05:20,524 >> Model weights saved in /content/gdrive/MyDrive/pr/output/checkpoint-1000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2037] 2021-11-14 16:05:20,529 >> tokenizer config file saved in /content/gdrive/MyDrive/pr/output/checkpoint-1000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2043] 2021-11-14 16:05:20,532 >> Special tokens file saved in /content/gdrive/MyDrive/pr/output/checkpoint-1000/special_tokens_map.json\n",
            "{'loss': 5.9025, 'learning_rate': 4.490316004077472e-05, 'epoch': 0.51}\n",
            " 10% 1500/14715 [16:01<2:10:52,  1.68it/s][INFO|trainer.py:1995] 2021-11-14 16:10:48,780 >> Saving model checkpoint to /content/gdrive/MyDrive/pr/output/checkpoint-1500\n",
            "[INFO|configuration_utils.py:417] 2021-11-14 16:10:48,785 >> Configuration saved in /content/gdrive/MyDrive/pr/output/checkpoint-1500/config.json\n",
            "[INFO|modeling_utils.py:1060] 2021-11-14 16:10:54,254 >> Model weights saved in /content/gdrive/MyDrive/pr/output/checkpoint-1500/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2037] 2021-11-14 16:10:54,260 >> tokenizer config file saved in /content/gdrive/MyDrive/pr/output/checkpoint-1500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2043] 2021-11-14 16:10:54,263 >> Special tokens file saved in /content/gdrive/MyDrive/pr/output/checkpoint-1500/special_tokens_map.json\n",
            "{'loss': 5.8222, 'learning_rate': 4.320421338769963e-05, 'epoch': 0.68}\n",
            " 14% 2000/14715 [21:32<2:06:09,  1.68it/s][INFO|trainer.py:1995] 2021-11-14 16:16:19,893 >> Saving model checkpoint to /content/gdrive/MyDrive/pr/output/checkpoint-2000\n",
            "[INFO|configuration_utils.py:417] 2021-11-14 16:16:19,898 >> Configuration saved in /content/gdrive/MyDrive/pr/output/checkpoint-2000/config.json\n",
            "[INFO|modeling_utils.py:1060] 2021-11-14 16:16:25,482 >> Model weights saved in /content/gdrive/MyDrive/pr/output/checkpoint-2000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2037] 2021-11-14 16:16:26,824 >> tokenizer config file saved in /content/gdrive/MyDrive/pr/output/checkpoint-2000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2043] 2021-11-14 16:16:26,828 >> Special tokens file saved in /content/gdrive/MyDrive/pr/output/checkpoint-2000/special_tokens_map.json\n",
            "{'loss': 5.7579, 'learning_rate': 4.150526673462454e-05, 'epoch': 0.85}\n",
            " 17% 2500/14715 [27:06<2:00:54,  1.68it/s][INFO|trainer.py:1995] 2021-11-14 16:21:54,545 >> Saving model checkpoint to /content/gdrive/MyDrive/pr/output/checkpoint-2500\n",
            "[INFO|configuration_utils.py:417] 2021-11-14 16:21:54,550 >> Configuration saved in /content/gdrive/MyDrive/pr/output/checkpoint-2500/config.json\n",
            "[INFO|modeling_utils.py:1060] 2021-11-14 16:21:59,566 >> Model weights saved in /content/gdrive/MyDrive/pr/output/checkpoint-2500/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2037] 2021-11-14 16:21:59,572 >> tokenizer config file saved in /content/gdrive/MyDrive/pr/output/checkpoint-2500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2043] 2021-11-14 16:21:59,575 >> Special tokens file saved in /content/gdrive/MyDrive/pr/output/checkpoint-2500/special_tokens_map.json\n",
            "{'loss': 5.6917, 'learning_rate': 3.980632008154944e-05, 'epoch': 1.02}\n",
            " 20% 3000/14715 [32:38<1:55:50,  1.69it/s][INFO|trainer.py:1995] 2021-11-14 16:27:25,923 >> Saving model checkpoint to /content/gdrive/MyDrive/pr/output/checkpoint-3000\n",
            "[INFO|configuration_utils.py:417] 2021-11-14 16:27:25,928 >> Configuration saved in /content/gdrive/MyDrive/pr/output/checkpoint-3000/config.json\n",
            "[INFO|modeling_utils.py:1060] 2021-11-14 16:27:31,313 >> Model weights saved in /content/gdrive/MyDrive/pr/output/checkpoint-3000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2037] 2021-11-14 16:27:31,318 >> tokenizer config file saved in /content/gdrive/MyDrive/pr/output/checkpoint-3000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2043] 2021-11-14 16:27:31,321 >> Special tokens file saved in /content/gdrive/MyDrive/pr/output/checkpoint-3000/special_tokens_map.json\n",
            "{'loss': 5.6034, 'learning_rate': 3.810737342847435e-05, 'epoch': 1.19}\n",
            " 24% 3500/14715 [38:07<1:51:01,  1.68it/s][INFO|trainer.py:1995] 2021-11-14 16:32:55,725 >> Saving model checkpoint to /content/gdrive/MyDrive/pr/output/checkpoint-3500\n",
            "[INFO|configuration_utils.py:417] 2021-11-14 16:32:55,735 >> Configuration saved in /content/gdrive/MyDrive/pr/output/checkpoint-3500/config.json\n",
            "[INFO|modeling_utils.py:1060] 2021-11-14 16:33:00,647 >> Model weights saved in /content/gdrive/MyDrive/pr/output/checkpoint-3500/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2037] 2021-11-14 16:33:00,656 >> tokenizer config file saved in /content/gdrive/MyDrive/pr/output/checkpoint-3500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2043] 2021-11-14 16:33:00,660 >> Special tokens file saved in /content/gdrive/MyDrive/pr/output/checkpoint-3500/special_tokens_map.json\n",
            "{'loss': 5.5604, 'learning_rate': 3.6408426775399255e-05, 'epoch': 1.36}\n",
            " 27% 4000/14715 [43:42<1:46:07,  1.68it/s][INFO|trainer.py:1995] 2021-11-14 16:38:29,969 >> Saving model checkpoint to /content/gdrive/MyDrive/pr/output/checkpoint-4000\n",
            "[INFO|configuration_utils.py:417] 2021-11-14 16:38:29,993 >> Configuration saved in /content/gdrive/MyDrive/pr/output/checkpoint-4000/config.json\n",
            "[INFO|modeling_utils.py:1060] 2021-11-14 16:38:37,382 >> Model weights saved in /content/gdrive/MyDrive/pr/output/checkpoint-4000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2037] 2021-11-14 16:38:37,387 >> tokenizer config file saved in /content/gdrive/MyDrive/pr/output/checkpoint-4000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2043] 2021-11-14 16:38:37,476 >> Special tokens file saved in /content/gdrive/MyDrive/pr/output/checkpoint-4000/special_tokens_map.json\n",
            "{'loss': 5.5282, 'learning_rate': 3.4709480122324164e-05, 'epoch': 1.53}\n",
            " 31% 4500/14715 [49:15<1:41:17,  1.68it/s][INFO|trainer.py:1995] 2021-11-14 16:44:03,396 >> Saving model checkpoint to /content/gdrive/MyDrive/pr/output/checkpoint-4500\n",
            "[INFO|configuration_utils.py:417] 2021-11-14 16:44:03,401 >> Configuration saved in /content/gdrive/MyDrive/pr/output/checkpoint-4500/config.json\n",
            "[INFO|modeling_utils.py:1060] 2021-11-14 16:44:09,016 >> Model weights saved in /content/gdrive/MyDrive/pr/output/checkpoint-4500/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2037] 2021-11-14 16:44:09,022 >> tokenizer config file saved in /content/gdrive/MyDrive/pr/output/checkpoint-4500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2043] 2021-11-14 16:44:09,025 >> Special tokens file saved in /content/gdrive/MyDrive/pr/output/checkpoint-4500/special_tokens_map.json\n",
            "{'loss': 5.4992, 'learning_rate': 3.3010533469249065e-05, 'epoch': 1.7}\n",
            " 34% 5000/14715 [54:47<1:36:44,  1.67it/s][INFO|trainer.py:1995] 2021-11-14 16:49:35,420 >> Saving model checkpoint to /content/gdrive/MyDrive/pr/output/checkpoint-5000\n",
            "[INFO|configuration_utils.py:417] 2021-11-14 16:49:35,428 >> Configuration saved in /content/gdrive/MyDrive/pr/output/checkpoint-5000/config.json\n",
            "[INFO|modeling_utils.py:1060] 2021-11-14 16:49:41,324 >> Model weights saved in /content/gdrive/MyDrive/pr/output/checkpoint-5000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2037] 2021-11-14 16:49:41,331 >> tokenizer config file saved in /content/gdrive/MyDrive/pr/output/checkpoint-5000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2043] 2021-11-14 16:49:41,334 >> Special tokens file saved in /content/gdrive/MyDrive/pr/output/checkpoint-5000/special_tokens_map.json\n",
            "{'loss': 5.4681, 'learning_rate': 3.1311586816173974e-05, 'epoch': 1.87}\n",
            " 37% 5500/14715 [1:00:22<1:31:27,  1.68it/s][INFO|trainer.py:1995] 2021-11-14 16:55:09,926 >> Saving model checkpoint to /content/gdrive/MyDrive/pr/output/checkpoint-5500\n",
            "[INFO|configuration_utils.py:417] 2021-11-14 16:55:09,930 >> Configuration saved in /content/gdrive/MyDrive/pr/output/checkpoint-5500/config.json\n",
            "[INFO|modeling_utils.py:1060] 2021-11-14 16:55:14,945 >> Model weights saved in /content/gdrive/MyDrive/pr/output/checkpoint-5500/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2037] 2021-11-14 16:55:14,953 >> tokenizer config file saved in /content/gdrive/MyDrive/pr/output/checkpoint-5500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2043] 2021-11-14 16:55:14,957 >> Special tokens file saved in /content/gdrive/MyDrive/pr/output/checkpoint-5500/special_tokens_map.json\n",
            "{'loss': 5.4313, 'learning_rate': 2.9612640163098882e-05, 'epoch': 2.04}\n",
            " 41% 6000/14715 [1:05:56<1:26:18,  1.68it/s][INFO|trainer.py:1995] 2021-11-14 17:00:44,484 >> Saving model checkpoint to /content/gdrive/MyDrive/pr/output/checkpoint-6000\n",
            "[INFO|configuration_utils.py:417] 2021-11-14 17:00:44,490 >> Configuration saved in /content/gdrive/MyDrive/pr/output/checkpoint-6000/config.json\n",
            "[INFO|modeling_utils.py:1060] 2021-11-14 17:00:50,612 >> Model weights saved in /content/gdrive/MyDrive/pr/output/checkpoint-6000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2037] 2021-11-14 17:00:50,617 >> tokenizer config file saved in /content/gdrive/MyDrive/pr/output/checkpoint-6000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2043] 2021-11-14 17:00:50,622 >> Special tokens file saved in /content/gdrive/MyDrive/pr/output/checkpoint-6000/special_tokens_map.json\n",
            "{'loss': 5.3518, 'learning_rate': 2.7913693510023787e-05, 'epoch': 2.21}\n",
            " 44% 6500/14715 [1:11:27<1:21:13,  1.69it/s][INFO|trainer.py:1995] 2021-11-14 17:06:14,933 >> Saving model checkpoint to /content/gdrive/MyDrive/pr/output/checkpoint-6500\n",
            "[INFO|configuration_utils.py:417] 2021-11-14 17:06:14,937 >> Configuration saved in /content/gdrive/MyDrive/pr/output/checkpoint-6500/config.json\n",
            "[INFO|modeling_utils.py:1060] 2021-11-14 17:06:21,392 >> Model weights saved in /content/gdrive/MyDrive/pr/output/checkpoint-6500/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2037] 2021-11-14 17:06:21,398 >> tokenizer config file saved in /content/gdrive/MyDrive/pr/output/checkpoint-6500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2043] 2021-11-14 17:06:21,403 >> Special tokens file saved in /content/gdrive/MyDrive/pr/output/checkpoint-6500/special_tokens_map.json\n",
            "{'loss': 5.3399, 'learning_rate': 2.6214746856948692e-05, 'epoch': 2.38}\n",
            " 48% 7000/14715 [1:16:57<1:16:18,  1.68it/s][INFO|trainer.py:1995] 2021-11-14 17:11:45,154 >> Saving model checkpoint to /content/gdrive/MyDrive/pr/output/checkpoint-7000\n",
            "[INFO|configuration_utils.py:417] 2021-11-14 17:11:45,160 >> Configuration saved in /content/gdrive/MyDrive/pr/output/checkpoint-7000/config.json\n",
            "[INFO|modeling_utils.py:1060] 2021-11-14 17:11:49,980 >> Model weights saved in /content/gdrive/MyDrive/pr/output/checkpoint-7000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2037] 2021-11-14 17:11:49,986 >> tokenizer config file saved in /content/gdrive/MyDrive/pr/output/checkpoint-7000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2043] 2021-11-14 17:11:49,989 >> Special tokens file saved in /content/gdrive/MyDrive/pr/output/checkpoint-7000/special_tokens_map.json\n",
            "{'loss': 5.3352, 'learning_rate': 2.45158002038736e-05, 'epoch': 2.55}\n",
            " 51% 7500/14715 [1:22:27<1:11:21,  1.69it/s][INFO|trainer.py:1995] 2021-11-14 17:17:15,305 >> Saving model checkpoint to /content/gdrive/MyDrive/pr/output/checkpoint-7500\n",
            "[INFO|configuration_utils.py:417] 2021-11-14 17:17:15,310 >> Configuration saved in /content/gdrive/MyDrive/pr/output/checkpoint-7500/config.json\n",
            "[INFO|modeling_utils.py:1060] 2021-11-14 17:17:20,651 >> Model weights saved in /content/gdrive/MyDrive/pr/output/checkpoint-7500/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2037] 2021-11-14 17:17:20,657 >> tokenizer config file saved in /content/gdrive/MyDrive/pr/output/checkpoint-7500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2043] 2021-11-14 17:17:20,661 >> Special tokens file saved in /content/gdrive/MyDrive/pr/output/checkpoint-7500/special_tokens_map.json\n",
            "{'loss': 5.3093, 'learning_rate': 2.2816853550798505e-05, 'epoch': 2.72}\n",
            " 54% 8000/14715 [1:28:02<1:06:33,  1.68it/s][INFO|trainer.py:1995] 2021-11-14 17:22:49,765 >> Saving model checkpoint to /content/gdrive/MyDrive/pr/output/checkpoint-8000\n",
            "[INFO|configuration_utils.py:417] 2021-11-14 17:22:49,771 >> Configuration saved in /content/gdrive/MyDrive/pr/output/checkpoint-8000/config.json\n",
            "[INFO|modeling_utils.py:1060] 2021-11-14 17:22:56,074 >> Model weights saved in /content/gdrive/MyDrive/pr/output/checkpoint-8000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2037] 2021-11-14 17:22:56,082 >> tokenizer config file saved in /content/gdrive/MyDrive/pr/output/checkpoint-8000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2043] 2021-11-14 17:22:56,084 >> Special tokens file saved in /content/gdrive/MyDrive/pr/output/checkpoint-8000/special_tokens_map.json\n",
            "{'loss': 5.3158, 'learning_rate': 2.1117906897723413e-05, 'epoch': 2.89}\n",
            " 58% 8500/14715 [1:33:36<1:01:29,  1.68it/s][INFO|trainer.py:1995] 2021-11-14 17:28:24,444 >> Saving model checkpoint to /content/gdrive/MyDrive/pr/output/checkpoint-8500\n",
            "[INFO|configuration_utils.py:417] 2021-11-14 17:28:24,450 >> Configuration saved in /content/gdrive/MyDrive/pr/output/checkpoint-8500/config.json\n",
            "[INFO|modeling_utils.py:1060] 2021-11-14 17:28:29,734 >> Model weights saved in /content/gdrive/MyDrive/pr/output/checkpoint-8500/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2037] 2021-11-14 17:28:29,739 >> tokenizer config file saved in /content/gdrive/MyDrive/pr/output/checkpoint-8500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2043] 2021-11-14 17:28:29,742 >> Special tokens file saved in /content/gdrive/MyDrive/pr/output/checkpoint-8500/special_tokens_map.json\n",
            "{'loss': 5.2596, 'learning_rate': 1.9418960244648318e-05, 'epoch': 3.06}\n",
            " 61% 9000/14715 [1:39:09<56:29,  1.69it/s][INFO|trainer.py:1995] 2021-11-14 17:33:56,786 >> Saving model checkpoint to /content/gdrive/MyDrive/pr/output/checkpoint-9000\n",
            "[INFO|configuration_utils.py:417] 2021-11-14 17:33:56,795 >> Configuration saved in /content/gdrive/MyDrive/pr/output/checkpoint-9000/config.json\n",
            "[INFO|modeling_utils.py:1060] 2021-11-14 17:34:01,987 >> Model weights saved in /content/gdrive/MyDrive/pr/output/checkpoint-9000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2037] 2021-11-14 17:34:01,995 >> tokenizer config file saved in /content/gdrive/MyDrive/pr/output/checkpoint-9000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2043] 2021-11-14 17:34:01,999 >> Special tokens file saved in /content/gdrive/MyDrive/pr/output/checkpoint-9000/special_tokens_map.json\n",
            "{'loss': 5.2034, 'learning_rate': 1.7720013591573227e-05, 'epoch': 3.23}\n",
            " 65% 9500/14715 [1:44:39<51:53,  1.68it/s][INFO|trainer.py:1995] 2021-11-14 17:39:27,204 >> Saving model checkpoint to /content/gdrive/MyDrive/pr/output/checkpoint-9500\n",
            "[INFO|configuration_utils.py:417] 2021-11-14 17:39:27,212 >> Configuration saved in /content/gdrive/MyDrive/pr/output/checkpoint-9500/config.json\n",
            "[INFO|modeling_utils.py:1060] 2021-11-14 17:39:32,311 >> Model weights saved in /content/gdrive/MyDrive/pr/output/checkpoint-9500/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2037] 2021-11-14 17:39:33,854 >> tokenizer config file saved in /content/gdrive/MyDrive/pr/output/checkpoint-9500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2043] 2021-11-14 17:39:33,857 >> Special tokens file saved in /content/gdrive/MyDrive/pr/output/checkpoint-9500/special_tokens_map.json\n",
            "{'loss': 5.2025, 'learning_rate': 1.602106693849813e-05, 'epoch': 3.4}\n",
            " 68% 10000/14715 [1:50:12<46:44,  1.68it/s][INFO|trainer.py:1995] 2021-11-14 17:45:00,053 >> Saving model checkpoint to /content/gdrive/MyDrive/pr/output/checkpoint-10000\n",
            "[INFO|configuration_utils.py:417] 2021-11-14 17:45:00,059 >> Configuration saved in /content/gdrive/MyDrive/pr/output/checkpoint-10000/config.json\n",
            "[INFO|modeling_utils.py:1060] 2021-11-14 17:45:05,785 >> Model weights saved in /content/gdrive/MyDrive/pr/output/checkpoint-10000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2037] 2021-11-14 17:45:05,789 >> tokenizer config file saved in /content/gdrive/MyDrive/pr/output/checkpoint-10000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2043] 2021-11-14 17:45:05,793 >> Special tokens file saved in /content/gdrive/MyDrive/pr/output/checkpoint-10000/special_tokens_map.json\n",
            "{'loss': 5.2078, 'learning_rate': 1.4322120285423038e-05, 'epoch': 3.57}\n",
            " 71% 10500/14715 [1:55:46<41:45,  1.68it/s][INFO|trainer.py:1995] 2021-11-14 17:50:33,874 >> Saving model checkpoint to /content/gdrive/MyDrive/pr/output/checkpoint-10500\n",
            "[INFO|configuration_utils.py:417] 2021-11-14 17:50:33,880 >> Configuration saved in /content/gdrive/MyDrive/pr/output/checkpoint-10500/config.json\n",
            "[INFO|modeling_utils.py:1060] 2021-11-14 17:50:39,870 >> Model weights saved in /content/gdrive/MyDrive/pr/output/checkpoint-10500/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2037] 2021-11-14 17:50:39,875 >> tokenizer config file saved in /content/gdrive/MyDrive/pr/output/checkpoint-10500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2043] 2021-11-14 17:50:39,879 >> Special tokens file saved in /content/gdrive/MyDrive/pr/output/checkpoint-10500/special_tokens_map.json\n",
            "{'loss': 5.1855, 'learning_rate': 1.2623173632347945e-05, 'epoch': 3.74}\n",
            " 75% 11000/14715 [2:01:19<36:44,  1.69it/s][INFO|trainer.py:1995] 2021-11-14 17:56:06,810 >> Saving model checkpoint to /content/gdrive/MyDrive/pr/output/checkpoint-11000\n",
            "[INFO|configuration_utils.py:417] 2021-11-14 17:56:06,814 >> Configuration saved in /content/gdrive/MyDrive/pr/output/checkpoint-11000/config.json\n",
            "[INFO|modeling_utils.py:1060] 2021-11-14 17:56:12,269 >> Model weights saved in /content/gdrive/MyDrive/pr/output/checkpoint-11000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2037] 2021-11-14 17:56:12,362 >> tokenizer config file saved in /content/gdrive/MyDrive/pr/output/checkpoint-11000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2043] 2021-11-14 17:56:12,482 >> Special tokens file saved in /content/gdrive/MyDrive/pr/output/checkpoint-11000/special_tokens_map.json\n",
            "{'loss': 5.1877, 'learning_rate': 1.0924226979272851e-05, 'epoch': 3.91}\n",
            " 78% 11500/14715 [2:06:50<31:49,  1.68it/s][INFO|trainer.py:1995] 2021-11-14 18:01:38,377 >> Saving model checkpoint to /content/gdrive/MyDrive/pr/output/checkpoint-11500\n",
            "[INFO|configuration_utils.py:417] 2021-11-14 18:01:38,382 >> Configuration saved in /content/gdrive/MyDrive/pr/output/checkpoint-11500/config.json\n",
            "[INFO|modeling_utils.py:1060] 2021-11-14 18:01:43,577 >> Model weights saved in /content/gdrive/MyDrive/pr/output/checkpoint-11500/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2037] 2021-11-14 18:01:43,584 >> tokenizer config file saved in /content/gdrive/MyDrive/pr/output/checkpoint-11500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2043] 2021-11-14 18:01:43,596 >> Special tokens file saved in /content/gdrive/MyDrive/pr/output/checkpoint-11500/special_tokens_map.json\n",
            "{'loss': 5.1598, 'learning_rate': 9.225280326197758e-06, 'epoch': 4.08}\n",
            " 82% 12000/14715 [2:12:24<27:05,  1.67it/s][INFO|trainer.py:1995] 2021-11-14 18:07:12,109 >> Saving model checkpoint to /content/gdrive/MyDrive/pr/output/checkpoint-12000\n",
            "[INFO|configuration_utils.py:417] 2021-11-14 18:07:12,114 >> Configuration saved in /content/gdrive/MyDrive/pr/output/checkpoint-12000/config.json\n",
            "[INFO|modeling_utils.py:1060] 2021-11-14 18:07:18,171 >> Model weights saved in /content/gdrive/MyDrive/pr/output/checkpoint-12000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2037] 2021-11-14 18:07:18,176 >> tokenizer config file saved in /content/gdrive/MyDrive/pr/output/checkpoint-12000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2043] 2021-11-14 18:07:18,179 >> Special tokens file saved in /content/gdrive/MyDrive/pr/output/checkpoint-12000/special_tokens_map.json\n",
            "{'loss': 5.1251, 'learning_rate': 7.526333673122664e-06, 'epoch': 4.25}\n",
            " 85% 12500/14715 [2:17:53<21:56,  1.68it/s][INFO|trainer.py:1995] 2021-11-14 18:12:41,659 >> Saving model checkpoint to /content/gdrive/MyDrive/pr/output/checkpoint-12500\n",
            "[INFO|configuration_utils.py:417] 2021-11-14 18:12:41,663 >> Configuration saved in /content/gdrive/MyDrive/pr/output/checkpoint-12500/config.json\n",
            "[INFO|modeling_utils.py:1060] 2021-11-14 18:12:46,696 >> Model weights saved in /content/gdrive/MyDrive/pr/output/checkpoint-12500/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2037] 2021-11-14 18:12:46,701 >> tokenizer config file saved in /content/gdrive/MyDrive/pr/output/checkpoint-12500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2043] 2021-11-14 18:12:46,704 >> Special tokens file saved in /content/gdrive/MyDrive/pr/output/checkpoint-12500/special_tokens_map.json\n",
            "{'loss': 5.124, 'learning_rate': 5.8273870200475705e-06, 'epoch': 4.42}\n",
            " 88% 13000/14715 [2:23:25<16:58,  1.68it/s][INFO|trainer.py:1995] 2021-11-14 18:18:13,202 >> Saving model checkpoint to /content/gdrive/MyDrive/pr/output/checkpoint-13000\n",
            "[INFO|configuration_utils.py:417] 2021-11-14 18:18:13,207 >> Configuration saved in /content/gdrive/MyDrive/pr/output/checkpoint-13000/config.json\n",
            "[INFO|modeling_utils.py:1060] 2021-11-14 18:18:18,047 >> Model weights saved in /content/gdrive/MyDrive/pr/output/checkpoint-13000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2037] 2021-11-14 18:18:18,240 >> tokenizer config file saved in /content/gdrive/MyDrive/pr/output/checkpoint-13000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2043] 2021-11-14 18:18:18,245 >> Special tokens file saved in /content/gdrive/MyDrive/pr/output/checkpoint-13000/special_tokens_map.json\n",
            "{'loss': 5.1289, 'learning_rate': 4.128440366972477e-06, 'epoch': 4.59}\n",
            " 92% 13500/14715 [2:28:55<12:02,  1.68it/s][INFO|trainer.py:1995] 2021-11-14 18:23:43,584 >> Saving model checkpoint to /content/gdrive/MyDrive/pr/output/checkpoint-13500\n",
            "[INFO|configuration_utils.py:417] 2021-11-14 18:23:43,589 >> Configuration saved in /content/gdrive/MyDrive/pr/output/checkpoint-13500/config.json\n",
            "[INFO|modeling_utils.py:1060] 2021-11-14 18:23:49,424 >> Model weights saved in /content/gdrive/MyDrive/pr/output/checkpoint-13500/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2037] 2021-11-14 18:23:49,430 >> tokenizer config file saved in /content/gdrive/MyDrive/pr/output/checkpoint-13500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2043] 2021-11-14 18:23:50,524 >> Special tokens file saved in /content/gdrive/MyDrive/pr/output/checkpoint-13500/special_tokens_map.json\n",
            "{'loss': 5.1056, 'learning_rate': 2.4294937138973837e-06, 'epoch': 4.76}\n",
            " 95% 14000/14715 [2:34:30<07:05,  1.68it/s][INFO|trainer.py:1995] 2021-11-14 18:29:18,470 >> Saving model checkpoint to /content/gdrive/MyDrive/pr/output/checkpoint-14000\n",
            "[INFO|configuration_utils.py:417] 2021-11-14 18:29:18,474 >> Configuration saved in /content/gdrive/MyDrive/pr/output/checkpoint-14000/config.json\n",
            "[INFO|modeling_utils.py:1060] 2021-11-14 18:29:23,685 >> Model weights saved in /content/gdrive/MyDrive/pr/output/checkpoint-14000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2037] 2021-11-14 18:29:23,691 >> tokenizer config file saved in /content/gdrive/MyDrive/pr/output/checkpoint-14000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2043] 2021-11-14 18:29:23,694 >> Special tokens file saved in /content/gdrive/MyDrive/pr/output/checkpoint-14000/special_tokens_map.json\n",
            "{'loss': 5.1046, 'learning_rate': 7.305470608222901e-07, 'epoch': 4.93}\n",
            " 99% 14500/14715 [2:40:04<02:07,  1.69it/s][INFO|trainer.py:1995] 2021-11-14 18:34:52,168 >> Saving model checkpoint to /content/gdrive/MyDrive/pr/output/checkpoint-14500\n",
            "[INFO|configuration_utils.py:417] 2021-11-14 18:34:52,172 >> Configuration saved in /content/gdrive/MyDrive/pr/output/checkpoint-14500/config.json\n",
            "[INFO|modeling_utils.py:1060] 2021-11-14 18:34:57,166 >> Model weights saved in /content/gdrive/MyDrive/pr/output/checkpoint-14500/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2037] 2021-11-14 18:34:57,171 >> tokenizer config file saved in /content/gdrive/MyDrive/pr/output/checkpoint-14500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2043] 2021-11-14 18:34:57,175 >> Special tokens file saved in /content/gdrive/MyDrive/pr/output/checkpoint-14500/special_tokens_map.json\n",
            "100% 14715/14715 [2:42:46<00:00,  1.68it/s][INFO|trainer.py:1409] 2021-11-14 18:37:34,704 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 9766.984, 'train_samples_per_second': 1.507, 'train_steps_per_second': 1.507, 'train_loss': 5.43108790323437, 'epoch': 5.0}\n",
            "100% 14715/14715 [2:42:46<00:00,  1.51it/s]\n",
            "[INFO|trainer.py:1995] 2021-11-14 18:37:34,720 >> Saving model checkpoint to /content/gdrive/MyDrive/pr/output\n",
            "[INFO|configuration_utils.py:417] 2021-11-14 18:37:34,724 >> Configuration saved in /content/gdrive/MyDrive/pr/output/config.json\n",
            "[INFO|modeling_utils.py:1060] 2021-11-14 18:37:39,944 >> Model weights saved in /content/gdrive/MyDrive/pr/output/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2037] 2021-11-14 18:37:39,948 >> tokenizer config file saved in /content/gdrive/MyDrive/pr/output/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2043] 2021-11-14 18:37:39,951 >> Special tokens file saved in /content/gdrive/MyDrive/pr/output/special_tokens_map.json\n",
            "***** train metrics *****\n",
            "  epoch                    =        5.0\n",
            "  train_loss               =     5.4311\n",
            "  train_runtime            = 2:42:46.98\n",
            "  train_samples            =       2943\n",
            "  train_samples_per_second =      1.507\n",
            "  train_steps_per_second   =      1.507\n",
            "[INFO|modelcard.py:449] 2021-11-14 18:37:41,759 >> Dropping the following result as it does not have all the necessary fields:\n",
            "{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNbfA5aqF7Jy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "620877C7tgxI"
      },
      "source": [
        "# gen_token"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nj5d0vDtF7G3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11b5279e-cd3e-41d0-de11-0b43ad531db5"
      },
      "source": [
        "paths = [\"/content/gdrive/MyDrive/pr/limricks_input_test_1124.txt\"]\n",
        "\n",
        "# Initialize a tokenizer\n",
        "tokenizer = BertWordPieceTokenizer()\n",
        "\n",
        "# special_tokens=['<|endoftext|>']\n",
        "special_tokens=['=', '-']\n",
        "# syllables_path = \"/content/gdrive/MyDrive/pr/syllables.txt\"\n",
        "# with open(syllables_path) as f:\n",
        "#   lines = f.readlines()\n",
        "#   for line in lines:\n",
        "#     special_tokens.append(\"<\" + line.strip('\\n') + \">\")\n",
        "# f.close()  \n",
        "print(special_tokens)\n",
        "\n",
        "# Customize training\n",
        "tokenizer.train(files=paths, vocab_size=30_000, min_frequency=2, special_tokens=special_tokens)\n",
        "\n",
        "# special_tokens_dict = {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'pad_token': '<PAD>'}\n",
        "# tokenizer.add_special_tokens(special_tokens_dict)\n",
        "\n",
        "# Save files to disk\n",
        "tokenizer.save_model(\"/content/gdrive/MyDrive/pr/tokenizers\", \"tokenizer1124\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['=', '-']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/gdrive/MyDrive/pr/tokenizers/tokenizer1124-vocab.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUOeAUxSF7D2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6191f21d-39c3-4be6-e05a-9e6c64ca161a"
      },
      "source": [
        "output = tokenizer.encode(\"capn jack was washed over the side-his crew searched but found not hair nor hide-no longer the helm-but the deep benthic realm-is where jack will forever reside-\")\n",
        "print(output.tokens)\n",
        "print(output.ids)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ca', '##p', '##n', 'jack', 'was', 'was', '##hed', 'o', '##ver', 'the', 's', '##ide', '-', 'his', 'cre', '##w', 's', '##e', '##ar', '##ch', '##ed', 'but', 'f', '##ound', 'not', 'ha', '##ir', 'n', '##or', 'hide', '-', 'n', '##o', 'l', '##on', '##g', '##er', 'the', 'he', '##lm', '-', 'but', 'the', 'd', '##eep', 'be', '##nt', '##hi', '##c', 're', '##a', '##lm', '-', 'is', 'where', 'jack', 'wi', '##ll', 'for', '##e', '##ver', 'reside', '-']\n",
            "[85, 37, 30, 210, 68, 68, 189, 16, 126, 53, 20, 76, 1, 146, 139, 48, 20, 39, 75, 103, 83, 111, 7, 190, 152, 145, 185, 15, 80, 147, 1, 15, 29, 13, 56, 44, 55, 53, 86, 167, 1, 111, 53, 5, 107, 73, 74, 183, 33, 115, 32, 167, 1, 78, 202, 210, 166, 69, 93, 39, 126, 214, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIbfiqh8783a",
        "outputId": "1f164836-a807-4d90-ccd9-eef4a5dcc20b"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\"/content/gdrive/MyDrive/pr/tokenizers/tokenizer[SEP]--vocab.txt\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1645: FutureWarning: Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated and won't be possible anymore in v5. Use a model identifier or the path to a directory instead.\n",
            "  FutureWarning,\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19AAUdiY-K3W",
        "outputId": "20a710e5-9407-4901-d62a-578534b19bb6"
      },
      "source": [
        "sequence = \"A Titan RTX has 24GB of VRAM\"\n",
        "tokenized_sequence = tokenizer.tokenize(sequence)\n",
        "print(tokenized_sequence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['a', 'titan', 'r', '##t', '##x', 'has', '[UNK]', 'of', 'v', '##ram']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MYnHHJw_BGw",
        "outputId": "744c8d67-ca6f-43b8-94fb-0ef209c031d3"
      },
      "source": [
        "inputs = tokenizer(sequence)\n",
        "encoded_sequence = inputs[\"input_ids\"]\n",
        "print(encoded_sequence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[30001, 4, 8956, 21, 33, 43, 313, None, 87, 25, 4820, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqokPa4V6sr1"
      },
      "source": [
        "sequence_a = \"This is a short sequence.\"\n",
        "sequence_b = \"This is a rather long sequence. It is at least longer than the sequence A.\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-FVc0Ec6_lU",
        "outputId": "716e5b2d-cf30-4a2e-a6cd-23d24751f5f5"
      },
      "source": [
        "encoded_sequence_a = tokenizer(sequence_a)[\"input_ids\"]\n",
        "encoded_sequence_b = tokenizer(sequence_b)[\"input_ids\"]\n",
        "\n",
        "len(encoded_sequence_a), len(encoded_sequence_b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8, 19)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjeUA3BM6_dP"
      },
      "source": [
        "padded_sequences = tokenizer([sequence_a, sequence_b], padding=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHzEV5HQ6sid",
        "outputId": "634c3207-89e6-4957-93a6-611ecd1a37da"
      },
      "source": [
        "o = padded_sequences[\"input_ids\"]\n",
        "print(type(o[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFSrXmzD9-AY",
        "outputId": "c9d6d583-b022-442e-806c-1d063f0e323b"
      },
      "source": [
        "padded_sequences[\"attention_mask\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              " [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UYK2ZkbCOdf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDPjBC38COX9"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from syllabipy.sonoripy import SonoriPy\n",
        "import json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qRTXC7DIdVH"
      },
      "source": [
        "line = \"fuck syllables get away\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsk6ZQ5nrhT-"
      },
      "source": [
        "def concatenate(dit, subDit):\n",
        "  dit['input_ids'].extend(subDit['input_ids'])\n",
        "  dit['token_type_ids'].extend(subDit['token_type_ids'])\n",
        "  dit['attention_mask'].extend(subDit['attention_mask'])\n",
        "  return dit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXwyI2URCOKD",
        "outputId": "21f4a735-a78d-4b1e-ef3c-1a7688d6e266"
      },
      "source": [
        "dic = {'input_ids': [], 'token_type_ids': [], 'attention_mask': []}\n",
        "\n",
        "for word in line.split(' '):\n",
        "  syllable_list = SonoriPy(word)\n",
        "  syllable_str = ' '.join(syllable_list)\n",
        "\n",
        "  encoded_dict = tokenizer(word, syllable_str)\n",
        "  decoded = tokenizer.decode(encoded_dict[\"input_ids\"])\n",
        "  dic = concatenate(dic, encoded_dict)\n",
        "\n",
        "print(dic)\n",
        "decoded = tokenizer.decode(dic[\"input_ids\"])\n",
        "print(decoded)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [30001, 207, 0, 207, 0, 30001, 13295, 205, 122, 0, 280, 104, 1786, 23, 122, 0, 30001, 1976, 0, 1976, 0, 30001, 76, 0, 76, 0, 30001, 7999, 0, 7999, 0, 30001, 661, 1, 150, 0, 661, 1, 150, 0, 30001, 335, 0, 386, 133, 0, 30001, 10551, 0, 778, 23, 122, 0, 30001, 7999, 0, 7999, 0, 30001, 661, 0, 661, 0, 30001, 1976, 0, 1976, 0, 30001, 76, 0, 76, 0, 30001, 6497, 1, 512, 0, 6497, 1, 512, 0, 30001, 2646, 0, 2646, 0, 30001, 1678, 0, 388, 30, 366, 0, 30001, 267, 0, 267, 0, 30001, 4, 0, 4, 0, 30001, 5135, 1, 253, 0, 5135, 1, 23, 3395, 0, 30001, 19609, 0, 133, 12296, 928, 0, 30001, 83, 0, 83, 0, 30001, 80, 0, 80, 0, 30001, 4438, 1, 120, 0, 1532, 42, 715, 1, 120, 0, 30001, 104, 0, 104, 0, 30001, 6577, 37, 0, 4123, 3291, 0, 30001, 83, 0, 83, 0, 30001, 76, 0, 76, 0, 30001, 6497, 0, 6497, 0, 30001, 80, 0, 80, 0, 30001, 253, 0, 253, 0, 30001, 1837, 0, 1, 0, 1837, 0, 1, 0], 'token_type_ids': [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
            "[CLS] she [SEP] she [SEP] [CLS] adherently [SEP] ad he ren tly [SEP] [CLS] stuck [SEP] stuck [SEP] [CLS] to [SEP] to [SEP] [CLS] joes [SEP] joes [SEP] [CLS] plan - or [SEP] plan - or [SEP] [CLS] more [SEP] mo re [SEP] [CLS] aptly [SEP] ap tly [SEP] [CLS] joes [SEP] joes [SEP] [CLS] plan [SEP] plan [SEP] [CLS] stuck [SEP] stuck [SEP] [CLS] to [SEP] to [SEP] [CLS] jan - first [SEP] jan - first [SEP] [CLS] joe [SEP] joe [SEP] [CLS] wrote [SEP] wro te [SEP] [CLS] up [SEP] up [SEP] [CLS] a [SEP] a [SEP] [CLS] draft - then [SEP] draft - t hen [SEP] [CLS] reviewed [SEP] re vie wed [SEP] [CLS] it [SEP] it [SEP] [CLS] and [SEP] and [SEP] [CLS] laughed - as [SEP] laug hed - as [SEP] [CLS] he [SEP] he [SEP] [CLS] taped [SEP] ta ped [SEP] [CLS] it [SEP] it [SEP] [CLS] to [SEP] to [SEP] [CLS] jan [SEP] jan [SEP] [CLS] and [SEP] and [SEP] [CLS] then [SEP] then [SEP] [CLS] ran [SEP] - [SEP] ran [SEP] - [SEP]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "cSPK46xv999j",
        "outputId": "4f95ee71-7eec-485f-ec00-99fe49cd6619"
      },
      "source": [
        "input_path = '/content/gdrive/MyDrive/pr/limricks_end_with_[SEP]_sep_with_-.txt'\n",
        "\n",
        "dic = {'input_ids': [], 'token_type_ids': [], 'attention_mask': []}\n",
        "\n",
        "with open(input_path) as f_in:\n",
        "  lines = f_in.readlines()\n",
        "  for line in lines:\n",
        "    for word in line.split():\n",
        "      if (word == \"<|endoftext|>\"):\n",
        "        encoded_dict = tokenizer(word)\n",
        "\n",
        "      else:\n",
        "        syllable_list = SonoriPy(word)\n",
        "        syllable_str = ' '.join(syllable_list)\n",
        "        encoded_dict = tokenizer(word, syllable_str)\n",
        "\n",
        "      dic = concatenate(dic, encoded_dict)\n",
        "\n",
        "# print(dic)\n",
        "print(dic['input_ids'])\n",
        "print(dic['token_type_ids'])\n",
        "print(dic['attention_mask'])\n",
        "# decoded = tokenizer.decode(dic[\"input_ids\"])\n",
        "# print(decoded)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-ddb25935299d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0msyllable_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSonoriPy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0msyllable_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msyllable_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mencoded_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyllable_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m       \u001b[0mdic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2449\u001b[0m                 \u001b[0mreturn_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2450\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2451\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2452\u001b[0m             )\n\u001b[1;32m   2453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mencode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2519\u001b[0m             \u001b[0mreturn_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2520\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2521\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2522\u001b[0m         )\n\u001b[1;32m   2523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36m_encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0mfirst_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m         \u001b[0msecond_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtext_pair\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m         return self.prepare_for_model(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36mget_input_ids\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m                 \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    602\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_tokens_to_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m                 \u001b[0mtokenized_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m                 \u001b[0mtokenized_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;31m# [\"This\", \" is\", \" something\", \"<special_token_1>\", \"else\"]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtokenized_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/tokenization_bert.py\u001b[0m in \u001b[0;36m_tokenize\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0msplit_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_basic_tokenize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnever_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_special_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                 \u001b[0;31m# If the token is part of the never_split set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mall_special_tokens\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1230\u001b[0m         \u001b[0mConvert\u001b[0m \u001b[0mtokens\u001b[0m \u001b[0mof\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtokenizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAddedToken\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mtype\u001b[0m \u001b[0mto\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m         \"\"\"\n\u001b[0;32m-> 1232\u001b[0;31m         \u001b[0mall_toks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_special_tokens_extended\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1233\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mall_toks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mall_special_tokens_extended\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1243\u001b[0m         \"\"\"\n\u001b[1;32m   1244\u001b[0m         \u001b[0mall_toks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1245\u001b[0;31m         \u001b[0mset_attr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial_tokens_map_extended\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1246\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mattr_value\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mset_attr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1247\u001b[0m             \u001b[0mall_toks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_toks\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr_value\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mattr_value\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mspecial_tokens_map_extended\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1217\u001b[0m         \"\"\"\n\u001b[1;32m   1218\u001b[0m         \u001b[0mset_attr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSPECIAL_TOKENS_ATTRIBUTES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0mattr_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mattr_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxIM_aM9994l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8b72175-8701-411f-8ce9-072ac48241e5"
      },
      "source": [
        "print(len(dic['input_ids']))\n",
        "print(len(dic['input_ids']))\n",
        "print(len(dic['token_type_ids']))\n",
        "print(len(dic['attention_mask']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14942643\n",
            "14942643\n",
            "14942643\n",
            "14942643\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEyFaBnbV8Ek"
      },
      "source": [
        "from transformers import GPT2Model, GPT2Config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkXTLuqPWTIw"
      },
      "source": [
        "configuration = GPT2Config()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMKdC4PJWWwo"
      },
      "source": [
        "model = GPT2Model(configuration)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VtDs0_7WYjn"
      },
      "source": [
        "configuration = model.config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELPOimtWWaXP"
      },
      "source": [
        "from transformers import GPT2Tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "c18eba9ec3594af79cb9278a45b37716",
            "e1a0fbd387e04392913a9e7a1f819bf2",
            "aebce9e2218549b28da292b9e0be6fc0",
            "7745cd0e139c48308345165bc958fed3",
            "3b6c487602604e66b2105e7382702176",
            "b2b665d1f13e47939ea2c2a4cce816ca",
            "0a07396c51d04617a660746d5833d9b9",
            "d8a986951461438da5cde657ca00101d",
            "abe8245c6f654f2c9fab32086c352bea",
            "3236249a91ee4675be6182f9986c4e27",
            "db722dd8dfdd4d4c9fdbc4405aa99ff3",
            "f182faf32f6c4fa9af1eacd46f87cbce",
            "c15bb8d570e04e9e9220f4d4fc894e22",
            "11e7511ffb03421289efea987aa49729",
            "0a69bcff12d7421fbc0efe65830c5f88",
            "ecec65ca0a74405ca94890817b20a273",
            "79cc9158720b4757b0f59092d566e44c",
            "696d8ee15d0347219bc2f2d0c3d1155a",
            "43de6c0f65d647e3b7da8a3727f8314e",
            "2f53fa9f61b242cbbae29e8e1e614651",
            "e32fc99e2ef3422194aa43e8f8a17ed5",
            "eb72792c857142af8cac11e833333658",
            "d48cb42e67384e048dfc4f23b0877368",
            "eb90bced1b6b41e5957f11d83393a993",
            "5785373b812e47efb31c68d9ecb56b56",
            "5dfcbf207aa94331a8fc9f32270a3ac7",
            "0c8c84cb7bf54ae89ab5c24a02b4aeab",
            "85788a1652ff48cb813cd4486d004491",
            "8653a1d9b9f34e53a11c34170456d76a",
            "e8b9b9ef173a423685f882ffcb40ec4a",
            "6b52a8b9bbae448d9511d617511bd272",
            "26616f8ee65b4c5ba139370fb38e3eab",
            "41ac1842c4c5419f80ddab6f4ea2ee9e",
            "67461cb30e184d26881164ac823529af",
            "79203d773f3942c0b37a38cfe9e472a7",
            "3a7ab6d927c444be93401bff8db4e1cc",
            "56b6052be5904862a6fecc53e659c034",
            "ecd35cb4880d461d9996a7d59fb2f62d",
            "0c272afc029449e98170debcba45d1ed",
            "42999472938a420c9106a893a17f5fab",
            "38bbee53c63843bea226f92ae96176b7",
            "9d88120aeec54d8984cdc769274ee565",
            "56f2fb1fbd724536abc1056b2b75bf27",
            "addb6172c76d41148be9c970f9b71d28"
          ]
        },
        "id": "Il7aMQazWjC8",
        "outputId": "88d782e2-9061-4d7a-ed47-cc84127e4173"
      },
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c18eba9ec3594af79cb9278a45b37716",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/0.99M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f182faf32f6c4fa9af1eacd46f87cbce",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d48cb42e67384e048dfc4f23b0877368",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "67461cb30e184d26881164ac823529af",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HeLeZfHyWjT-",
        "outputId": "48df6760-2daf-4db8-a5d2-87202375d6c7"
      },
      "source": [
        "tokenizer(\"Hello world\")['input_ids']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[15496, 995]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9XuErlGWmTU",
        "outputId": "64bc3bf9-afec-484e-e737-bec2527b3eb4"
      },
      "source": [
        "tokenizer(\" Hello world\")['input_ids']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[30001, 6318, 931, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXaWDG8ZWqA-"
      },
      "source": [
        "input_text = \"Here is some text to encode\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbNZaXlWXruX"
      },
      "source": [
        "# Customize training\n",
        "tokenizer.train(files=paths, vocab_size=52_000, min_frequency=2, special_tokens=[\n",
        "    \"<s>\",\n",
        "    \"<pad>\",\n",
        "    \"</s>\",\n",
        "    \"<unk>\",\n",
        "    \"<mask>\",\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNwF5i9iZOdb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSuytNuPZOxJ",
        "outputId": "20115e53-f667-4a9c-af52-1c92765f8ccc"
      },
      "source": [
        "from tokenizers import ByteLevelBPETokenizer\n",
        "\n",
        "paths = ['/content/gdrive/MyDrive/gpt2/limericks_test.txt']\n",
        "\n",
        "# Initialize a tokenizer\n",
        "tokenizer = ByteLevelBPETokenizer()\n",
        "\n",
        "special_tokens=['<|endoftext|>']\n",
        "\n",
        "# Customize training\n",
        "tokenizer.train(files=paths, vocab_size=52000, min_frequency=2, special_tokens=special_tokens)\n",
        "\n",
        "# Save files to disk\n",
        "tokenizer.save_model(\".\", \"poem\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['./poem-vocab.json', './poem-merges.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sx30VQAUgwv2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MM8oB4Z1Lv_g",
        "outputId": "87be564c-c501-456d-bd6b-1a3cff0ee78d"
      },
      "source": [
        "\n",
        "sequence_a = \"HuggingFace is based in NYC\"\n",
        "sequence_b = \"Where is HuggingFace based?\"\n",
        "\n",
        "encoded_dict = tokenizer(sequence_a, sequence_b)\n",
        "print(encoded_dict[\"input_ids\"])\n",
        "d = encoded_dict[\"input_ids\"]\n",
        "# decoded = tokenizer.decode(encoded_dict[\"input_ids\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[30001, 21452, 7563, 106, 4409, 81, 13906, 45, 0, 349, 106, 21452, 7563, 4409, None, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-EeZVJcLv8r",
        "outputId": "8e781e9d-f624-45de-b352-b1439310c50f"
      },
      "source": [
        "print(d)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[30001, 21452, 7563, 106, 4409, 81, 13906, 45, 0, 349, 106, 21452, 7563, 4409, None, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqPep-xdLv5X",
        "outputId": "0fa8f85f-6a43-4791-e257-680cb44e9ed9"
      },
      "source": [
        "tmp2 = [0 if v is None else v for v in d]\n",
        "print(tmp2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[30001, 21452, 7563, 106, 4409, 81, 13906, 45, 0, 349, 106, 21452, 7563, 4409, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftUPDObNLv2B"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSCZPHpQlj0T"
      },
      "source": [
        "# Type Id\n",
        "https://scottmduda.medium.com/generating-an-edgar-allen-poe-styled-poem-using-gpt-2-289801ded82c"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9W5hwPVPJ-Uy"
      },
      "source": [
        "from tokenizers import ByteLevelBPETokenizer\n",
        "from tokenizers import BertWordPieceTokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50ZlLwayJz95",
        "outputId": "a0adec9a-d8d4-4e46-e34e-f26a945b6669"
      },
      "source": [
        "!pip install syllabipy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting syllabipy\n",
            "  Downloading syllabipy-0.2.tar.gz (3.9 kB)\n",
            "Building wheels for collected packages: syllabipy\n",
            "  Building wheel for syllabipy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for syllabipy: filename=syllabipy-0.2-py3-none-any.whl size=5813 sha256=d611842c07fad1108eb1d167eb21701c1ac2fef36b9672e66003d197cf7d5821\n",
            "  Stored in directory: /root/.cache/pip/wheels/5a/43/1a/9078e0df36fa76df8c584c20b0eeb924ad8686d240b1a9646a\n",
            "Successfully built syllabipy\n",
            "Installing collected packages: syllabipy\n",
            "Successfully installed syllabipy-0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlkFEw42lkrY"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "\n",
        "import random\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "import torch\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, GPT2Config, AdamW, get_linear_schedule_with_warmup\n",
        "from torch.utils.data import Dataset, random_split, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from syllabipy.sonoripy import SonoriPy\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TAWZpdrlnKR"
      },
      "source": [
        "RANDOM_SEED = 73\n",
        "BATCH_SIZE = 1024\n",
        "EPOCHS = 8\n",
        "MAX_LEN = 1024"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQU7rBqK4ASN",
        "outputId": "c5e745a1-1855-4cc3-a78d-820454af58f1"
      },
      "source": [
        "paths = [\"/content/gdrive/MyDrive/pr/limericks_end_with_[SEP]_sep_with_-.txt\"]\n",
        "\n",
        "# Initialize a tokenizer\n",
        "tokenizer = BertWordPieceTokenizer()\n",
        "\n",
        "# special_tokens=['<|endoftext|>']\n",
        "special_tokens=['[SEP]', '-']\n",
        "# syllables_path = \"/content/gdrive/MyDrive/pr/syllables.txt\"\n",
        "# with open(syllables_path) as f:\n",
        "#   lines = f.readlines()\n",
        "#   for line in lines:\n",
        "#     special_tokens.append(\"<\" + line.strip('\\n') + \">\")\n",
        "# f.close()  \n",
        "print(special_tokens)\n",
        "\n",
        "# Customize training\n",
        "tokenizer.train(files=paths, vocab_size=30_000, min_frequency=2, special_tokens=special_tokens)\n",
        "\n",
        "# special_tokens_dict = {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'pad_token': '<PAD>'}\n",
        "# tokenizer.add_special_tokens(special_tokens_dict)\n",
        "\n",
        "# Save files to disk\n",
        "tokenizer.save_model(\"/content/gdrive/MyDrive/pr/tokenizers\", \"tokenizerTypeId\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[SEP]', '-']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/gdrive/MyDrive/pr/tokenizers/tokenizerTypeId-vocab.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p45W6KKj1Ztv",
        "outputId": "292ffcf5-0d34-4cbd-c9e7-fa2ac22d4e49"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\"/content/gdrive/MyDrive/pr/tokenizers/tokenizerTypeId-vocab.txt\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1645: FutureWarning: Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated and won't be possible anymore in v5. Use a model identifier or the path to a directory instead.\n",
            "  FutureWarning,\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2K-VLSA2pII",
        "outputId": "2c62a41c-0db2-479e-cc1c-e4b50f8cc0d6"
      },
      "source": [
        "print(len(tokenizer))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30003\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ket2nEQNrkUO",
        "outputId": "8f1f7fdf-9e46-4fc6-b2eb-4e8ae392de67"
      },
      "source": [
        "class PoePoemDataset(Dataset):\n",
        "    def __init__(self, data_path, tokenizer, gpt2_type='gpt2', max_length=MAX_LEN):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.input_ids = []\n",
        "        self.token_type_ids = []\n",
        "        self.attention_mask = []\n",
        "\n",
        "        with open(data_path) as f_in:\n",
        "          lines = f_in.readlines()\n",
        "          for line in lines:\n",
        "            for word in line.split():\n",
        "              if (word in special_tokens):\n",
        "                encodings_dict = tokenizer(word)\n",
        "              else:\n",
        "                syllable_list = SonoriPy(word)\n",
        "                syllable_str = ' '.join(syllable_list)\n",
        "                encodings_dict = tokenizer(word, syllable_str)\n",
        "\n",
        "              encodings_dict['input_ids'] = [0 if v is None else v for v in encodings_dict['input_ids']]\n",
        "              self.input_ids.extend(encodings_dict['input_ids'])\n",
        "              self.token_type_ids.extend(encodings_dict['token_type_ids'])\n",
        "              self.attention_mask.extend(encodings_dict['attention_mask'])\n",
        "\n",
        "        print(len(self.input_ids))\n",
        "        print(len(self.token_type_ids))\n",
        "        print(len(self.attention_mask))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.token_type_ids[idx], self.attention_mask[idx]\n",
        "        \n",
        "\n",
        "input_path = \"/content/gdrive/MyDrive/pr/limericks_end_with_[SEP]_sep_with_-.txt\"\n",
        "poem_stanza_dataset = PoePoemDataset(input_path, tokenizer, max_length=MAX_LEN)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14942623\n",
            "14942623\n",
            "14942623\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bxm0HN4M9Q_k"
      },
      "source": [
        "# def train_val_split(split, dataset):\n",
        "#     train_size = int(split * len(dataset))\n",
        "#     val_size = len(dataset) - train_size\n",
        "#     return train_size, val_size\n",
        "# poem_line_train_size, poem_line_val_size = train_val_split(0.8, poem_line_dataset)\n",
        "# poem_line_train_dataset, poem_line_val_dataset = random_split(poem_line_dataset, [poem_line_train_size, poem_line_val_size])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xlb88T-pB_7",
        "outputId": "91453fe1-4b1a-4f43-ab5c-930096f5c9fa"
      },
      "source": [
        "torch.cuda.manual_seed_all(RANDOM_SEED)\n",
        "random.seed(RANDOM_SEED)\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f52e6ae28f0>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BUucU6KpCOA"
      },
      "source": [
        "poem_stanza_dataloader = DataLoader(poem_stanza_dataset,\n",
        "                              sampler=RandomSampler(poem_stanza_dataset),\n",
        "                              batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tedYgvhaprKg"
      },
      "source": [
        "# helper function for logging time\n",
        "def format_time(elapsed):\n",
        "    return str(datetime.timedelta(seconds=int(round((elapsed)))))\n",
        "\n",
        "# hyperparameters\n",
        "learning_rate = 1e-4\n",
        "eps = 1e-8\n",
        "warmup_steps = 50\n",
        "\n",
        "# create text generation seed prompt\n",
        "device = torch.device('cuda')\n",
        "\n",
        "prompt = \"\"\n",
        "generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
        "generated = generated.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnvWw0H8932p",
        "outputId": "74891761-4874-4d7d-815a-763bc8cf2ea9"
      },
      "source": [
        "print(generated)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[30001,     0]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fy2OsgQQv0Dt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "c1e3d9f058d84ff5871b1dedb7b830d4",
            "f8ddba81585d407ab2cec0b1e736bbd4",
            "76e3cc498e0b4d4a9b13c95b6922bf7e",
            "848ca6841a3e45e1af2c0ae74fadd731",
            "9cfab8c2c3924968b9b1b47c3ba5dc24",
            "27bb13d4f2a8443398037d497c5cd683",
            "3230626405264061ac5dd0aea6006d1d",
            "5973aa2e0a654d8e92ab5094751ef02c",
            "86146e58b158477f98440292d68fa0d1",
            "5db1c9fb01214fe7898ec726c1bebd2a",
            "480149419b9941f797b24ac11abdbd63",
            "1d2adaac34694034a5018877f795dd49",
            "8f67a82b37d8428195d489032f2163d1",
            "0fab5e00f9a1440facf2509f723e188e",
            "c0f533a91ccb49378e8a2377b2a03200",
            "89a0cc7251f1456c96975611799d2eed",
            "35a1404b91ca46ffad4000e6daca1f90",
            "e0fdf0ae4079484ea1c40f76d80d9469",
            "adffb1973ded4381a620982c5ec25c97",
            "0e187dc320574ce9b339fc6447fa6b1a",
            "000e80c4c4454cb9a5b33afdfbceba4f",
            "bfb6efc8bb91453ea3d2bceb7f7be7e3"
          ]
        },
        "outputId": "ceca00e2-5d42-4db9-bdff-9fb3592bbc4a"
      },
      "source": [
        "configuration = GPT2Config(vocab_size=len(tokenizer), n_positions=MAX_LEN).from_pretrained('gpt2', output_hidden_states=True)\n",
        "\n",
        "# poem_stanza_model = GPT2LMHeadModel.from_pretrained('gpt2', config=configuration)\n",
        "poem_stanza_model = GPT2LMHeadModel\n",
        "poem_stanza_model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "poem_stanza_model.cuda()\n",
        "optimizer = AdamW(poem_stanza_model.parameters(), lr=learning_rate, eps=eps)\n",
        "\n",
        "total_steps = len(poem_stanza_dataloader) * EPOCHS\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps=warmup_steps,\n",
        "                                            num_training_steps=total_steps)\n",
        "\n",
        "start_time = time.time()\n",
        "poem_stanza_model = poem_stanza_model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c1e3d9f058d84ff5871b1dedb7b830d4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1d2adaac34694034a5018877f795dd49",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/523M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "eUdSXTPWqcVI",
        "outputId": "2547eb85-030d-42b3-c024-31df1486b087"
      },
      "source": [
        "for epoch_i in range(0, EPOCHS):\n",
        "\n",
        "    print(f'Epoch {epoch_i + 1} of {EPOCHS}')\n",
        "\n",
        "    t0 = time.time()\n",
        "    total_train_loss = 0\n",
        "    poem_stanza_model.train()\n",
        "\n",
        "    with tqdm(poem_stanza_dataloader) as t:\n",
        "      for step, batch in enumerate(t):\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[0].to(device)\n",
        "        b_token_type_ids = batch[1].to(device)\n",
        "        b_masks = batch[2].to(device)\n",
        "\n",
        "        poem_stanza_model.zero_grad()        \n",
        "\n",
        "        outputs = poem_stanza_model(b_input_ids,\n",
        "                                    labels=b_labels,\n",
        "                                    token_type_ids=b_token_type_ids,\n",
        "                                    attention_mask=b_masks)\n",
        "\n",
        "        loss = outputs[0]  \n",
        "\n",
        "        batch_loss = loss.item()\n",
        "        total_train_loss += batch_loss\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(poem_stanza_dataloader)       \n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(f'Average Training Loss: {avg_train_loss}. Epoch Training Time: {training_time}')\n",
        "\n",
        "#     t0 = time.time()\n",
        "\n",
        "#     poem_stanza_model.eval()\n",
        "\n",
        "#     total_eval_loss = 0\n",
        "#     nb_eval_steps = 0\n",
        "\n",
        "#     for batch in poem_stanza_val_dataloader:\n",
        "#         b_input_ids = batch[0].to(device)\n",
        "#         b_labels = batch[0].to(device)\n",
        "#         b_token_type_ids = batch[1].to(device)\n",
        "#         b_masks = batch[2].to(device)\n",
        "\n",
        "#         with torch.no_grad():        \n",
        "#             outputs = poem_stanza_model(b_input_ids,\n",
        "#                                         labels=b_labels,\n",
        "#                                         token_type_ids=b_token_type_ids,\n",
        "#                                         attention_mask=b_masks)\n",
        "#             loss = outputs[0]  \n",
        "\n",
        "#         batch_loss = loss.item()\n",
        "#         total_eval_loss += batch_loss        \n",
        "\n",
        "#     avg_val_loss = total_eval_loss / len(poem_stanza_val_dataloader)\n",
        "\n",
        "\n",
        "#     print(f'Average Validation Loss: {avg_val_loss}')\n",
        "\n",
        "# print(f'Total Training Time: {format_time(time.time()-start_time)}')\n",
        "\n",
        "torch.save(poem_stanza_model.state_dict(), \"/content/gdrive/MyDrive/pr/models/poem_stanza_model.pth\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 of 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 14593/14593 [48:11<00:00,  5.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Training Loss: 4.625377530926815. Epoch Training Time: 0:48:12\n",
            "Epoch 2 of 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 14593/14593 [48:12<00:00,  5.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Training Loss: 4.623527061552849. Epoch Training Time: 0:48:13\n",
            "Epoch 3 of 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 1594/14593 [05:17<43:07,  5.02it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-61a936336511>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mtotal_train_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLFnPga9va5n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5549853c-d5a6-436a-d19b-6087f1946e96"
      },
      "source": [
        "poem_stanza_model.eval()\n",
        "\n",
        "sample_outputs = poem_stanza_model.generate(\n",
        "                                generated, \n",
        "                                do_sample=True,   \n",
        "                                top_k=50, \n",
        "                                max_length=MAX_LEN,\n",
        "                                top_p=0.95, \n",
        "                                num_return_sequences=3\n",
        "                                )\n",
        "\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "    print(\"{}: {}\\n\\n\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: ne me and so - its - its but - - - he - be - of i and the - - is for me be that for a a - a - - - a its - but the a the the a the - in my so my be he my - i me so in u - - - as that - the to with re for ti u but - - - its be u - a re but a - re is ti - - a re - but of - he that - - - a that - of so and re fors me ti to and - a - with for yo - re and - it and and - - t a ti the is - he in - its to a to re my in -s ti se it a - - be he for - me in a - se - - a - - that yo i to of its a - - the my - - on - in me me se - and on a the - i a on - to - - - on on of for - me in - - - - yo of i - re - - - yo - of re - and ves - ve - - on the ti me thes re a - - its - re - it a - of a and in is yo the - - to - - re - i my - - a the - - so - a ve a - it the - a to the to - - on a\n",
            "\n",
            "\n",
            "1: so - the the a of to - a t t of - i - - u - a - - and - me - the the the the - - a - ve - yo - - a that in - and of - and a - the a so so the to - of a of - me - that the a - - - - - of is and - yo and its be in - to ts - - re he it - to on - - iss ne so of a its so - - - se a to and and in - a - - the yo i - - he ve - - - re - - - and a a ve - to - ve - and my the a - that to - - the tis - - be - - he - its - - - - me - the - i in - i - it me u the the - - on - on t that the be i and - ti its and yo a it - but he re on re its and but re i -ss the it is ti - - thes yo of yo a a - - a u of on - a me and for - on be - to my a - a he and to to that - of be and - - - for - so se ti but - me - be the the and - to - is - the - the - a on - for be a - ti a -\n",
            "\n",
            "\n",
            "2: on is i ti a - - - is he - a - - so that that with - - t that u ti so it to a ofs to the - - - a the i to - - me ne - - - that in - and re a that a - a - the - its t - and the a - the i - - so with - and - - the in me - - - the me the - my thes - - - is but - - me its for and u to be se ti it - the in of t - a and - with a its and hes a ti re and he - - t yo - re ti on - - a - my is on re ne a -s a - - i that - the - a ne ve in - and be ne the a - of to u and a se - yo a a - - in my i - i so to the for a a - - the - t and me to ne - - - i on - a yo the to - the - i for of - a - a to - - in - ne a - - for a thes - - on me the my its a - is me - - my a i with - re to - of - of re - - - i -s so ti - re with ti a a ti that he and - and to to so - with - he to a - - - - it of - - to that to a -\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OgKaBxi-Iex"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}