{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "baseline576.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyE4PY81lP1Y"
      },
      "source": [
        "# 1. Environment setup "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLRjSLqJjJy8",
        "outputId": "6002375d-55ed-4791-8181-2771c50a0c66"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ori9DPB4k_ei",
        "outputId": "9f5c444a-29a1-42ff-c086-c3832d7613e0"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install syllabipy"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.12.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: syllabipy in /usr/local/lib/python3.7/dist-packages (0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dg5HUD5qlVZz"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "import random\n",
        "import time\n",
        "import datetime\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, GPT2Config, AdamW, get_linear_schedule_with_warmup\n",
        "from torch.utils.data import Dataset, random_split, DataLoader, RandomSampler, SequentialSampler\n",
        "from syllabipy.sonoripy import SonoriPy\n",
        "from transformers import BertTokenizer\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMPk8ZK4m81D"
      },
      "source": [
        "# 2. Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5T_eUwFnEGN"
      },
      "source": [
        "poem_df = pd.read_csv(\"/content/drive/MyDrive/GPT-2/limricks_end_with_[SEP]_sep_with_-.csv\")\n",
        "poem_df = poem_df.fillna(\"\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfjZyII0nYOZ"
      },
      "source": [
        "# 3. Process Text and Create Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPQfTHBEzYJA"
      },
      "source": [
        "batch_size = 32\n",
        "epochs = 20\n",
        "max_len = 60\n",
        "device = torch.device('cuda')\n",
        "learning_rate = 1e-4\n",
        "eps = 1e-8"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jrm-aur0nbll",
        "outputId": "0a3c65fa-61ca-44a3-bfa0-2c2b18994aa0"
      },
      "source": [
        "word_tokenizer = BertTokenizer.from_pretrained(\"/content/drive/MyDrive/GPT-2/tokenizer[SEP]--vocab.txt\")\n",
        "syl_tokenizer = BertTokenizer.from_pretrained(\"/content/drive/MyDrive/GPT-2/fre_1_syllables-vocab.txt\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1645: FutureWarning: Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated and won't be possible anymore in v5. Use a model identifier or the path to a directory instead.\n",
            "  FutureWarning,\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0p3SxBZU7rWd",
        "outputId": "5be15ee0-73cf-4a5b-aa57-5f8d6a0a8574"
      },
      "source": [
        "print(\"Length of word_tokenizer : {}\".format(len(word_tokenizer)))\n",
        "print(\"Length of syl_tokenizer : {}\". format(len(syl_tokenizer)))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of word_tokenizer : 30003\n",
            "Length of syl_tokenizer : 22383\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bA4PHl0W8duG"
      },
      "source": [
        "class PoemDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, data, tokenizer, max_length=max_len):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "        self.data = data\n",
        "        \n",
        "    def __len__(self):\n",
        "        \n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        encodings_dict = self.tokenizer(self.data[idx],\n",
        "                                        truncation=True,\n",
        "                                        max_length=self.max_length,\n",
        "                                        padding='max_length'\n",
        "                                        )\n",
        "        input_ids = encodings_dict['input_ids']\n",
        "        if None in input_ids:\n",
        "          input_ids = torch.zeros(self.max_length)\n",
        "          attention_mask = torch.zeros(self.max_length)\n",
        "        else:\n",
        "          input_ids = torch.tensor(encodings_dict['input_ids'])\n",
        "          attention_mask = torch.tensor(encodings_dict['attention_mask'])\n",
        "        input_ids = input_ids.type(torch.LongTensor)\n",
        "        return input_ids, attention_mask        "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qc12VnG2_YRz"
      },
      "source": [
        "poem_dataset = PoemDataset(poem_df.iloc[:, 0].values, word_tokenizer, max_len)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKEeoLPzncvE"
      },
      "source": [
        "# 4. Train/Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlZfwq4tnt6t"
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkrDnJPYnv0c"
      },
      "source": [
        "# 5. Instantiate DataLoaders and Define Model Creation Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2UbCalrn3Jk"
      },
      "source": [
        "poem_dataloader = DataLoader(poem_dataset, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIoYX8Evn84K"
      },
      "source": [
        "# 6. Create Poem Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ckesl5DqFarE"
      },
      "source": [
        "## 6.1 Sylliabification Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpFzFUMZo-oS"
      },
      "source": [
        "## 6.2 Modify gpt2 architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPbE5Jeo6CO3",
        "outputId": "c14a23a1-ddcd-42c1-cc05-5829c128d6bb"
      },
      "source": [
        "configuration = GPT2Config(vocab_size=len(word_tokenizer), n_positions=max_len, n_embd=768)\n",
        "model = GPT2LMHeadModel(config=configuration)\n",
        "print(model)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPT2LMHeadModel(\n",
            "  (transformer): GPT2Model(\n",
            "    (wte): Embedding(30003, 768)\n",
            "    (wpe): Embedding(60, 768)\n",
            "    (drop): Dropout(p=0.1, inplace=False)\n",
            "    (h): ModuleList(\n",
            "      (0): GPT2Block(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (1): GPT2Block(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (2): GPT2Block(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (3): GPT2Block(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (4): GPT2Block(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (5): GPT2Block(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (6): GPT2Block(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (7): GPT2Block(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (8): GPT2Block(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (9): GPT2Block(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (10): GPT2Block(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (11): GPT2Block(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (lm_head): Linear(in_features=768, out_features=30003, bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8lFLJIBx2Ev"
      },
      "source": [
        "# 6.3 Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRfshf9Lx62H",
        "outputId": "8e77dc3f-1718-4abf-803e-1789f4c9e6a5"
      },
      "source": [
        "model.cuda()\n",
        "optimizer = AdamW(model.parameters(), lr=learning_rate, eps=eps)\n",
        "# loaded = torch.load(\"/content/drive/MyDrive/GPT-2/mmodel.pth\")\n",
        "# model.load_state_dict(loaded)\n",
        "# optimizer.load_state_dict(loaded['optimizer_state_dict'])\n",
        "total_steps = len(poem_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=50, num_training_steps=total_steps)\n",
        "start_time = time.time()\n",
        "model = model.to(device)\n",
        "for epoch_i in range(100):\n",
        "\n",
        "    print('Epoch: ', epoch_i, '\\tlr: ', optimizer.param_groups[0]['lr'])\n",
        "\n",
        "    t0 = time.time()\n",
        "    total_train_loss = 0\n",
        "    model.train()\n",
        "\n",
        "    for batch in tqdm(poem_dataloader):\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[0].to(device)\n",
        "        b_masks = batch[1].to(device)\n",
        "\n",
        "        model.zero_grad()        \n",
        "\n",
        "        outputs = model(b_input_ids,\n",
        "                        labels=b_labels,\n",
        "                        attention_mask=b_masks,\n",
        "                        token_type_ids=None)\n",
        "\n",
        "        loss = outputs[0]  \n",
        "\n",
        "        batch_loss = loss.item()\n",
        "        total_train_loss += batch_loss\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(poem_dataloader)       \n",
        "    training_time = (time.time() - t0)\n",
        "    torch.save({'epoch': epoch_i,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict()}, '/content/drive/MyDrive/GPT-2/baseline768/epoch' + str(epoch_i) \n",
        "        + 'lr' + str('%.8f' % optimizer.param_groups[0]['lr']) + 'loss' + str('%.4f' % avg_train_loss) + '.pth')\n",
        "    print(f'Average Training Loss: {avg_train_loss}. Epoch Training Time: {training_time}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  0 \tlr:  0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2766/2766 [12:41<00:00,  3.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Training Loss: 3.8434493883054324. Epoch Training Time: 761.8387937545776\n",
            "Epoch:  1 \tlr:  9.508594174054641e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2766/2766 [12:41<00:00,  3.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Training Loss: 3.414946602551039. Epoch Training Time: 761.5912117958069\n",
            "Epoch:  2 \tlr:  9.008141849104396e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2766/2766 [12:41<00:00,  3.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Training Loss: 3.1899254303088846. Epoch Training Time: 761.9366409778595\n",
            "Epoch:  3 \tlr:  8.507689524154153e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2766/2766 [12:42<00:00,  3.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Training Loss: 3.0058184178601293. Epoch Training Time: 762.7969658374786\n",
            "Epoch:  4 \tlr:  8.007237199203909e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  4%|▍         | 116/2766 [00:32<12:07,  3.64it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHKDEsz9x0Xb",
        "outputId": "564cfe74-e044-4554-c72b-d3b3bffa21b3"
      },
      "source": [
        "state_dict = torch.load('/content/drive/MyDrive/GPT-2/baseline/epoch20lr0.00000000loss1.5441.pth')\n",
        "model.load_state_dict(state_dict['model_state_dict'])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVZO24RnoC0T"
      },
      "source": [
        "# 7. Generate Poem Stanzas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fm0xphgtoGgZ",
        "outputId": "62d5da7e-5a84-4b90-ea3f-8bbf2e46dc89"
      },
      "source": [
        "prompt = \"[CLS]\"\n",
        "generated = torch.tensor(word_tokenizer.encode(prompt)).unsqueeze(0)\n",
        "generated = generated.to(device)\n",
        "model.cuda()\n",
        "model.eval()\n",
        "sample_outputs = model.generate(\n",
        "                                generated, \n",
        "                                do_sample=True,   \n",
        "                                top_k=25, \n",
        "                                max_length=60,\n",
        "                                top_p=0.95, \n",
        "                                num_return_sequences=50)\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "    print(\"{}: {}\\n\".format(i, word_tokenizer.decode(sample_output, skip_special_tokens=True)))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: \n",
            "\n",
            "1: ##al need - or slow comprehension - the topic prevention - or worse a delusion in greed\n",
            "\n",
            "2: or vision - or any notion - or merely a guise or contusion\n",
            "\n",
            "3: \n",
            "\n",
            "4: ##ic direction - its mass should suffice - or the whole bit of ice - are these\n",
            "\n",
            "5: which you ive got - point just two point nine - or one is a pair - count the samples would have they been shot\n",
            "\n",
            "6: as these days - should be much to be seen - wearing only a scene - or a parnasi plenty of phase\n",
            "\n",
            "7: \n",
            "\n",
            "8: ##ic youd found - or these matters exciting - or given a positive sound\n",
            "\n",
            "9: ##ic surprise\n",
            "\n",
            "10: \n",
            "\n",
            "11: \n",
            "\n",
            "12: that rise - or small pains to please - its the point of a sneeze - would ensue if i hadnt a prize\n",
            "\n",
            "13: \n",
            "\n",
            "14: not far too near - your new cranium died - by mere matter the point that i fear\n",
            "\n",
            "15: ##al law meant - due to smelling the sound - the extent of ones mind - what we havent been shaved so he went\n",
            "\n",
            "16: \n",
            "\n",
            "17: ##al strain - a suggestion - or logic or mystic - or serious matter in pain\n",
            "\n",
            "18: which tend to be blurred - not much time turned too far - nor a smidgen of tar - is the point where you try to affirm\n",
            "\n",
            "19: ##al threat blurred - by its points - by design and such tools - are its minus a hundred and one\n",
            "\n",
            "20: which youre liable - to be much exceeding - its meaning youre citing -\n",
            "\n",
            "21: ##ialisation - point point or direction - the topic reaction or mission\n",
            "\n",
            "22: ##ic direction - its particle zero - then pause used to carry - attention or reason to mention\n",
            "\n",
            "23: ##al need for its price - should you feel elated - when once had abated - those charges were lacking in mice\n",
            "\n",
            "24: \n",
            "\n",
            "25: as much sense - or the nerve to be seen - when the rest is transparent to stealth\n",
            "\n",
            "26: ##ic decline - or parables heard - but dont bother the word - could have only an art sort of mine\n",
            "\n",
            "27: or section - made - the topic fruition - or malapore means just direction\n",
            "\n",
            "28: which end - its location - or mentionion we see - a deletion or lessening sin\n",
            "\n",
            "29: which means - should be slow to end - the direction or end - or explicit efflux of scenes\n",
            "\n",
            "30: \n",
            "\n",
            "31: ##ant to be - then descendant and end - was the point to the end - its the angle thats meant to be\n",
            "\n",
            "32: \n",
            "\n",
            "33: \n",
            "\n",
            "34: not stirred - or two was intended - but lacking intended - or multiplication required\n",
            "\n",
            "35: \n",
            "\n",
            "36: ##ic its station - direction or reaching - the height of hot flashing - or bold comprehension\n",
            "\n",
            "37: \n",
            "\n",
            "38: \n",
            "\n",
            "39: ##ary doubt - its direction or learning - or lacking a hearing - or suitable from comprehension\n",
            "\n",
            "40: \n",
            "\n",
            "41: ##ial threat - condorticular - or parriesnian - the bodys or joints just the threat\n",
            "\n",
            "42: or direction - its shape should they mention - the size or position\n",
            "\n",
            "43: which bent - its gyration - might cause consternation - that caesura means not a intent\n",
            "\n",
            "44: ##ial direction - its aim was precise - should this island suffice - or a negative vertical question\n",
            "\n",
            "45: ##ic decline - point the knee was akin - to the veins near the eye - deuterotics still coming to whine\n",
            "\n",
            "46: ##al binders - its mass tend to be - a crassobia - or merely a hint of mankinds\n",
            "\n",
            "47: which endic - direction to blur - the whole point is its end\n",
            "\n",
            "48: \n",
            "\n",
            "49: that means - too too much correction - direction to oneself\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_IRBeQR9YF-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}